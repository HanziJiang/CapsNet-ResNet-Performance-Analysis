{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_pkx4McDDItG",
        "XcYm7y8rECqg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiQpTflFkuqi"
      },
      "source": [
        "# Capsule Neural Network (CapsNet) Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDxJ_A_0Gnt9"
      },
      "source": [
        "Implementation of the paper [Dynamic Routing Between Capsules](https://arxiv.org/pdf/1710.09829.pdf) by Sara Sabour, Nicholas Frosst, and Geoffrey E. Hinton. Used [jindongwang/Pytorch-CapsuleNet](https://github.com/jindongwang/Pytorch-CapsuleNet) and [laubonghaudoi/CapsNet_guide_PyTorch](https://github.com/laubonghaudoi/CapsNet_guide_PyTorch) to clarify some confusions, and borrowed some code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pkx4McDDItG"
      },
      "source": [
        "## Setup PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peSdN_P8CElk",
        "outputId": "0831c8f6-f277-40f6-8b70-68dd12434d7f"
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install matplotlib\n",
        "!pip install import-ipynb\n",
        "!pip install tqdm\n",
        "!pip install pytorch_extras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp37-none-any.whl size=2976 sha256=c0a615f208e633f5fb8e40067102a0abc47ee3ae2f8ca3c5f0b111b8a995db80\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Collecting pytorch_extras\n",
            "  Downloading https://files.pythonhosted.org/packages/66/79/42d7d9a78c27eb897b14790c9759dd9a991f67bc987e9e137527a68db9dc/pytorch-extras-0.1.3.tar.gz\n",
            "Building wheels for collected packages: pytorch-extras\n",
            "  Building wheel for pytorch-extras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-extras: filename=pytorch_extras-0.1.3-cp37-none-any.whl size=2833 sha256=8eaa185455f6b77e50c7bacfef82236cd08e1c05ccda15f07284cbb0a09717c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/7c/5a/f27d4088adfe722cb280d523a1ed9eeb33be11b8d3a653292a\n",
            "Successfully built pytorch-extras\n",
            "Installing collected packages: pytorch-extras\n",
            "Successfully installed pytorch-extras-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMdBumXa75tw",
        "outputId": "ea9c9fdd-313a-46d8-e9e8-7c6c8be59f17"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"mnt\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at mnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlYHtO737_dA",
        "outputId": "b012b6d8-4b95-4ddf-eb6e-48e401f3b48e"
      },
      "source": [
        "%cd \"mnt/My Drive\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mnt/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsZEHMrIEVz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af343b67-9667-4229-841a-e0838b9d9bbc"
      },
      "source": [
        "import torch\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_extras\n",
        "import torch.nn as nn\n",
        "import torchvision.utils as tv_utils\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import import_ipynb\n",
        "import load_DrawData\n",
        "import numpy as np\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "# %mkdir -p /content/project/\n",
        "# %cd /content/project/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from load_DrawData.ipynb\n",
            "Collecting ndjson\n",
            "  Downloading https://files.pythonhosted.org/packages/70/c9/04ba0056011ba96a58163ebfd666d8385300bd12da1afe661a5a147758d7/ndjson-0.3.1-py2.py3-none-any.whl\n",
            "Installing collected packages: ndjson\n",
            "Successfully installed ndjson-0.3.1\n",
            "Collecting cairocffi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ca/0bffed5116d21251469df200448667e90acaa5131edea869b44a3fbc73d0/cairocffi-1.2.0.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.20)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.2.0-cp37-none-any.whl size=89548 sha256=4594b485a0e979b2a8454cbcca02efbd052d03fb2acf6382e364851fb4c42118\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/76/48/f1effadceea83b32e7d957dd0f92db4db8b537d7b72b4ef374\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.2.0\n",
            "mkdir: cannot create directory ‘quickDrawData’: File exists\n",
            "gs://quickdraw_dataset/full/simplified/apple.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/apple.ndjson...\n",
            "| [1/1 files][ 56.1 MiB/ 56.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/56.1 MiB.                                     \n",
            "gs://quickdraw_dataset/full/simplified/face.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/face.ndjson...\n",
            "/ [1/1 files][ 89.4 MiB/ 89.4 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/89.4 MiB.                                     \n",
            "Mounted at /content/drive\n",
            "7 420\n",
            "3 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcYm7y8rECqg"
      },
      "source": [
        "## CapsNet Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC4zxyWWeF-k"
      },
      "source": [
        "def squash(s):\n",
        "    '''Non-linear \"squashing\" function to ensure that short vectors get shrunk \n",
        "    to almost zero length and long vectors get shrunk to a length slightly \n",
        "    below 1. Equation (1) in the paper.\n",
        "    \n",
        "    Input:\n",
        "      s: \ttotal input vector\n",
        "    \n",
        "    Output:\n",
        "      squashed output vector\n",
        "    '''\n",
        "    norm_sqrd = torch.sum(s**2, dim=2, keepdim=True)\n",
        "    return (norm_sqrd / (1 + norm_sqrd)) * (s / (torch.sqrt(norm_sqrd) + 1e-8))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdGH3V4jJPmQ"
      },
      "source": [
        "class PrimaryCapsules(nn.Module):\n",
        "    '''The layer after Conv1. Section 4 of the paper.\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PrimaryCapsules, self).__init__()\n",
        "        self.capsules = nn.ModuleList(\n",
        "            [nn.Conv2d(in_channels=256,\n",
        "                    out_channels=8,\n",
        "                    kernel_size=9,\n",
        "                    stride=2)\n",
        "            for i in range(32)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''Section 4 of the paper.\n",
        "\n",
        "        Input:\n",
        "        x: outut of the ReLUConv1 layer, of shape (batch_size x 256 x 20 x 20)\n",
        "\n",
        "        Output:\n",
        "        squashed PrimaryCapsules output tensor, of shape (batch_size x 1152 x 8)\n",
        "        '''\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        # Get the output of each primary capsule; combine and prepare them to \n",
        "        # serve as the input to the next layer (DoodleCapsules)\n",
        "        all_u = []\n",
        "        for cap in self.capsules:\n",
        "            u = cap(x)  # (batch_size x 8 x 6 x 6)\n",
        "            u = u.view(batch_size, 8, 36, 1)  # (batch_size x 8 x 36 x 1)\n",
        "            all_u.append(u)\n",
        "        all_u = torch.cat(all_u, dim=3)  # (batch_size x 8 x 36 x 32)\n",
        "        all_u = all_u.view(batch_size, 8, -1)  # (batch_size x 8 x 1152)\n",
        "        all_u = torch.transpose(all_u, 1, 2)  # (batch_size x 1152 x 8)\n",
        "        all_u = squash(all_u)  # (batch_size x 1152 x 8)\n",
        "        \n",
        "        return all_u"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz1tFdzkaHyP"
      },
      "source": [
        "class DoodleCapsules(nn.Module):\n",
        "    '''The layer after PrimaryCapsules. Section 4 of the paper.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        super(DoodleCapsules, self).__init__()\n",
        "        self.opt = opt\n",
        "        self.W = nn.Parameter(torch.randn(1, 1152, opt.n_classes, 8, 16))\n",
        "    \n",
        "    def forward(self, u):\n",
        "        '''Equation (2) and Procedure 1 in the paper.\n",
        "\n",
        "        Input:\n",
        "        u: output of the PrimaryCapsules layer, of shape (batch_size x 8)\n",
        "\n",
        "        Output:\n",
        "        output tensor of the DoodleCapsules layer, of shape (batch_size x 1152 x n_classes x 1)\n",
        "        '''\n",
        "        batch_size = u.size(0)\n",
        "        \n",
        "        u = torch.unsqueeze(u, dim=2)  # (batch_size x 1 x 8)\n",
        "        u = torch.unsqueeze(u, dim=2)  # (batch_size x 1 x 1 x 8)\n",
        "        u_hat = torch.matmul(u, self.W).squeeze()  # (batch_size x 1152 x n_classes x 16)\n",
        "\n",
        "        b = Variable(torch.zeros(batch_size, 1152, self.opt.n_classes, 1))  # (batch_size x 1152 x n_classes x 1)\n",
        "        if self.opt.use_cuda & torch.cuda.is_available(): b = b.cuda()\n",
        "\n",
        "        for i in range(self.opt.iterations):\n",
        "            c = F.softmax(b, dim=2)  # (batch_size x 1152 x n_classes x 1)\n",
        "            s = torch.sum(u_hat * c, dim=1)  # (batch_size x n_classes x 16)\n",
        "            v = squash(s)  # (batch_size x n_classes x 16)\n",
        "            b = b + torch.sum(u_hat * v.unsqueeze(1), dim=3, keepdim=True)  # (batch_size x 1152 x n_classes x 1)\n",
        "        \n",
        "        return v  # (batch_size x n_classes x 16)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-k05aXUmDs8"
      },
      "source": [
        "class DoodleDecoder(nn.Module):\n",
        "    '''Decoder structure to reconstruct the doodle from the output of the DoodleCapsules layer.\n",
        "    Section 4 of the paper. For an illustrative explaination, see Figure 2 of the paper.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        super(DoodleDecoder, self).__init__()\n",
        "        self.opt = opt\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(opt.n_classes * 16, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, opt.height * opt.width),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, v, target):\n",
        "        '''Takes a 16-dimensional vector v from the *correct* DoodleCapsules, and \n",
        "        learns to decode it into an image of a doodle. Mask out the other (n_classes - 1) classes.\n",
        "        Section 4 of the paper. For an illustrative explaination, see Figure 2 of the paper.\n",
        "\n",
        "        Input:\n",
        "        v: output of DoodleCapsules, of shape (batch_size x n_classes x 16)\n",
        "        target: one-hot targets, of shape (batch_size, n_classes)\n",
        "\n",
        "        Output:\n",
        "        decoder constructed images, of shape (batch_size x 784)\n",
        "        '''\n",
        "        # TODO: the true target or the most probable?\n",
        "        # correct = torch.sqrt((v ** 2).sum(2))  # (batch_size x n_classes)\n",
        "        # correct = F.softmax(correct, dim=0)  # (batch_size x n_classes)\n",
        "        # correct = correct.max(dim=1)[1]  # (batch_size)\n",
        "        batch_size = v.size(0)\n",
        "\n",
        "        # Create the mask, which is 1 only for the correct class and 0 otherwise\n",
        "        mask = target.type(torch.FloatTensor).unsqueeze(-1)  # (batch_size x n_classes x 1)\n",
        "        mask = torch.repeat_interleave(mask, 16, dim=2)  # (batch_size x n_classes x 16)\n",
        "        if self.opt.use_cuda & torch.cuda.is_available(): mask = mask.cuda()\n",
        "        assert(mask.size() == torch.Size([batch_size, 2, 16]))\n",
        "        \n",
        "        masked = (v * mask).view(batch_size, -1)  # (batch_size x n_classes x 16)\n",
        "        result = self.layers(masked)  # (batch_size x 784)\n",
        "        assert(result.size() == torch.Size([batch_size, 784]))\n",
        "        \n",
        "        return result"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH6pouLtXQnx"
      },
      "source": [
        "class CapsuleNetwork(nn.Module):\n",
        "    '''Consists of a ReLU Convolution layer, a PrimaryCapsules layer, a DoodleCapsules\n",
        "    layer, and a Decoder layer. Section 4 of the paper.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        super(CapsuleNetwork, self).__init__()\n",
        "        self.opt = opt\n",
        "        self.ReLUConv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.PrimaryCapsules = PrimaryCapsules()\n",
        "        self.DoodleCapsules = DoodleCapsules(opt)\n",
        "        self.DoodleDecoder = DoodleDecoder(opt)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        '''Section 4 of the paper.\n",
        "\n",
        "        Input:\n",
        "        the input to the network, of shape (batch_size x 28 x 28)\n",
        "\n",
        "        Output:\n",
        "        the output of the network, of shape (batch_size x n_classes x 16)\n",
        "        '''\n",
        "        v = torch.unsqueeze(x, 1)\n",
        "        v = self.ReLUConv1(v)  # (batch_size x 256 x 20 x 20)\n",
        "        v = self.PrimaryCapsules(v)  # (batch_size x 1152 x 8)\n",
        "        v = self.DoodleCapsules(v)  # (batch_size x n_classes x 16)\n",
        "        return v  # (batch_size x n_classes x 16)\n",
        "\n",
        "    def marginal_loss(self, v, target):\n",
        "        '''Section 3, Equation (4) of the paper.\n",
        "\n",
        "        Input:\n",
        "        v: the output of the network, of shape (batch_size x n_classes x 16)\n",
        "        target: the one-hot target, of shape (batch_size x n_classes)\n",
        "        lambd: a scalor for down-weighting of the loss for absent doodle classes\n",
        "        \n",
        "        Output:\n",
        "        marginal loss (a scalor summed over all batches and classes)\n",
        "        '''\n",
        "        v_norm = torch.sqrt((v ** 2).sum(dim=2))  # (batch_size x n_classes)\n",
        "        \n",
        "        zeros = torch.zeros(v_norm.size())  # (batch_size x n_classes)\n",
        "        if self.opt.use_cuda & torch.cuda.is_available(): zeros = zeros.cuda()\n",
        "        \n",
        "        max1 = torch.max(zeros, 0.9 - v_norm) ** 2  # (batch_size x n_classes)\n",
        "        max2 = torch.max(zeros, v_norm - 0.1) ** 2  # (batch_size x n_classes) \n",
        "        loss = target * max1 + (1 - target) * 0.5 * max2  # (batch_size x n_classes)\n",
        "        \n",
        "        return torch.sum(loss)  # scalor\n",
        "\n",
        "    def reconstruction_loss(self, data, reconstruction):\n",
        "        '''Reconstruction for regularization. Ecourages the doodle capsules to \n",
        "        encode the instantiation parameters of the input doodle. Section 4.1 of the paper.\n",
        "\n",
        "        Input:\n",
        "        data: the real image, of shape (batch_size, 28, 28)\n",
        "        reconstruction: the reconstructed image, of shape (batch_size, 784)\n",
        "\n",
        "        Output:\n",
        "        reconstruction loss (a scalor summed over all batches and classes)\n",
        "        '''\n",
        "        batch_size = data.size(0)\n",
        "        return torch.sum((reconstruction - data.view(batch_size, -1)) ** 2)\n",
        "\n",
        "    def loss(self, v, data, target):\n",
        "        '''Loss is marginal loss + 0.0005 * reconstruction loss. 0.0005 to ensure\n",
        "        the reconstruction loss does not dominate the training. Section 4.1 of the paper.\n",
        "\n",
        "        Input:\n",
        "        v: output of the network, of shape (batch_size x n_classes x 16)\n",
        "        target: one-hot target, of shape (batch_size x n_classes)\n",
        "        data: the input to the network (the image), of shape (batch_size, 28, 28)\n",
        "        \n",
        "        Output:\n",
        "        averaged loss (a scalor) over batches \n",
        "        averaged marginal loss (a scalor) over batches\n",
        "        averaged reconstruction loss (a scalor) over batches\n",
        "        '''\n",
        "        batch_size = data.size(0)\n",
        "        \n",
        "        marginal_loss = self.marginal_loss(v, target)  # scalor\n",
        "        \n",
        "        reconstruction = self.DoodleDecoder(v, target)  # (batch_size, 784)\n",
        "        reconstruction_loss = self.reconstruction_loss(data, reconstruction)  # scalor\n",
        "        \n",
        "        loss = marginal_loss + 0.0005 * reconstruction_loss  # scalor\n",
        "        \n",
        "        return loss/batch_size, marginal_loss/batch_size, reconstruction_loss/batch_size"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKPXAofhnYhK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Holn-KGHnvZH"
      },
      "source": [
        "def get_opts():\n",
        "    parser = argparse.ArgumentParser(description='CapsuleNetwork')\n",
        "    parser.add_argument('-batch_size', type=int, default=60)\n",
        "    parser.add_argument('-lr', type=float, default=1e-5)\n",
        "    parser.add_argument('-epochs', type=int, default=1000)\n",
        "    parser.add_argument('-width', type=int, default=28)\n",
        "    parser.add_argument('-height', type=int, default=28)\n",
        "    parser.add_argument('-n_classes', type=int, default=2)\n",
        "    parser.add_argument('-iterations', type=int, default=3)\n",
        "    parser.add_argument('-use_cuda', default=True)\n",
        "    parser.add_argument('-print_every', type=int, default=10)\n",
        "    parser.add_argument('-gamma', type=float, default=0.98)\n",
        "    opt, _ = parser.parse_known_args()\n",
        "    return opt"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCM0T0_1d5W"
      },
      "source": [
        "def test(opt, test_loader, model, epoch, num_batches):\n",
        "    sum_loss = 0\n",
        "    sum_marginal_loss = 0\n",
        "    sum_reconstruction_loss = 0\n",
        "    correct = 0\n",
        "    num_sample = len(test_loader.dataset)\n",
        "    num_batch = len(test_loader)\n",
        "\n",
        "    model.eval()\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(torch.float32)\n",
        "        target = target.to(torch.int64)\n",
        "        batch_size = data.size(0)\n",
        "        assert target.size() == torch.Size([batch_size, opt.n_classes])\n",
        "\n",
        "        # Use GPU if available\n",
        "        with torch.no_grad():\n",
        "            data, target = Variable(data), Variable(target)\n",
        "        if opt.use_cuda & torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output = model(data)  # (batch_size, n_classes, 16)\n",
        "        loss, marginal_loss, reconstruction_loss = model.loss(output, data, target)\n",
        "        sum_loss += loss.item()\n",
        "        sum_marginal_loss += marginal_loss.item()\n",
        "        sum_reconstruction_loss += reconstruction_loss.item()\n",
        "\n",
        "        norms = torch.sqrt(torch.sum(output**2, dim=2))  # (batch_size, n_classes)\n",
        "        pred = norms.data.max(1, keepdim=True)[1].type(torch.LongTensor)  # (batch_size, 1)\n",
        "        label = target.max(1, keepdim=True)[1].type(torch.LongTensor)  # (batch_size, 1)\n",
        "        correct += pred.eq(label.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    recons = model.DoodleDecoder(output, target)\n",
        "    recons = recons.view(batch_size, 1, 28, 28)\n",
        "    recons = tv_utils.make_grid(recons.data, normalize=True, scale_each=True)\n",
        "\n",
        "    sum_loss /= num_batch\n",
        "    sum_marginal_loss /= num_batch\n",
        "    sum_reconstruction_loss /= num_batch\n",
        "    \n",
        "    print('\\nTest loss: {:.4f}   Marginal loss: {:.4f}   Reconstruction loss: {:.4f}'.format(\n",
        "        sum_loss, sum_marginal_loss, sum_reconstruction_loss))\n",
        "    print('\\nAccuracy: {}/{} {:.4f}\\n'.format(correct, num_sample,\n",
        "        correct / num_sample))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcoOvQfb1bVn"
      },
      "source": [
        "def train(opt, train_loader, test_loader, model):\n",
        "    num_sample = len(train_loader.dataset)\n",
        "    num_batches = len(train_loader)\n",
        "    train_loss_list = []\n",
        "    loss_val = 0.\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, opt.gamma)\n",
        "    model.train()\n",
        "    for epoch in range(opt.epochs):\n",
        "        scheduler.step()\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data = data.to(torch.float32)\n",
        "            batch_size = data.size(0)\n",
        "            target = target.to(torch.int64)\n",
        "            assert target.size() == torch.Size([batch_size, opt.n_classes])\n",
        "\n",
        "            # Use GPU if available\n",
        "            with torch.no_grad():\n",
        "                data, target = Variable(data), Variable(target)\n",
        "            if opt.use_cuda & torch.cuda.is_available():\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "            output = model(data)\n",
        "            loss, marginal_loss, reconstruction_loss = model.loss(output, data, target)\n",
        "            loss_val = loss.item()\n",
        "\n",
        "            # if batch_idx % opt.print_every == 0:\n",
        "            #      tqdm.write('\\nEpoch: {}    Training loss: {:.4f}   Marginal loss: {:.4f}   Reconstruction loss: {:.4f}'.format(epoch, loss.item(), marginal_loss.item(), reconstruction_loss.item()))\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch % 50 == 0: \n",
        "            train_loss_list.append(loss_val)\n",
        "        if epoch % 100 == 0:\n",
        "            print('Epoch: {}'.format(epoch))\n",
        "            print('Learning rate: {:.2e}'.format(scheduler.get_last_lr()[0]))\n",
        "            test(opt, test_loader, model, epoch, num_batches) \n",
        "    fig = plt.figure()\n",
        "    plt.plot([i for i in range(len(train_loss_list))], train_loss_list, '-')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4zXW1i3p1uq8",
        "outputId": "6d0e6ccc-9405-491e-a905-04ef16e1cad5"
      },
      "source": [
        "opt = get_opts()\n",
        "\n",
        "model = CapsuleNetwork(opt)\n",
        "if opt.use_cuda & torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "train_loader = load_DrawData.train_loader\n",
        "test_loader = load_DrawData.val_loader\n",
        "\n",
        "train(opt, train_loader, test_loader, model)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Learning rate: 9.80e-06\n",
            "\n",
            "Test loss: 3506.3309   Marginal loss: 0.4050   Reconstruction loss: 7011851.6667\n",
            "\n",
            "Accuracy: 140/180 0.7778\n",
            "\n",
            "Epoch: 100\n",
            "Learning rate: 1.30e-06\n",
            "\n",
            "Test loss: 3502.4740   Marginal loss: 0.4050   Reconstruction loss: 7004137.8333\n",
            "\n",
            "Accuracy: 137/180 0.7611\n",
            "\n",
            "Epoch: 200\n",
            "Learning rate: 1.72e-07\n",
            "\n",
            "Test loss: 3501.5273   Marginal loss: 0.4050   Reconstruction loss: 7002244.1667\n",
            "\n",
            "Accuracy: 140/180 0.7778\n",
            "\n",
            "Epoch: 300\n",
            "Learning rate: 2.29e-08\n",
            "\n",
            "Test loss: 3501.4102   Marginal loss: 0.4050   Reconstruction loss: 7002010.3333\n",
            "\n",
            "Accuracy: 143/180 0.7944\n",
            "\n",
            "Epoch: 400\n",
            "Learning rate: 3.03e-09\n",
            "\n",
            "Test loss: 3501.3953   Marginal loss: 0.4050   Reconstruction loss: 7001980.5000\n",
            "\n",
            "Accuracy: 143/180 0.7944\n",
            "\n",
            "Epoch: 500\n",
            "Learning rate: 4.02e-10\n",
            "\n",
            "Test loss: 3501.3937   Marginal loss: 0.4050   Reconstruction loss: 7001977.1667\n",
            "\n",
            "Accuracy: 141/180 0.7833\n",
            "\n",
            "Epoch: 600\n",
            "Learning rate: 5.33e-11\n",
            "\n",
            "Test loss: 3501.3937   Marginal loss: 0.4050   Reconstruction loss: 7001977.1667\n",
            "\n",
            "Accuracy: 145/180 0.8056\n",
            "\n",
            "Epoch: 700\n",
            "Learning rate: 7.07e-12\n",
            "\n",
            "Test loss: 3501.3937   Marginal loss: 0.4050   Reconstruction loss: 7001977.1667\n",
            "\n",
            "Accuracy: 143/180 0.7944\n",
            "\n",
            "Epoch: 800\n",
            "Learning rate: 9.38e-13\n",
            "\n",
            "Test loss: 3501.3937   Marginal loss: 0.4050   Reconstruction loss: 7001977.1667\n",
            "\n",
            "Accuracy: 143/180 0.7944\n",
            "\n",
            "Epoch: 900\n",
            "Learning rate: 1.24e-13\n",
            "\n",
            "Test loss: 3501.3937   Marginal loss: 0.4050   Reconstruction loss: 7001977.1667\n",
            "\n",
            "Accuracy: 142/180 0.7889\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2DDy51S3eEa",
        "outputId": "8d28fd7d-aee1-458f-c9ac-41eeb77dc17b"
      },
      "source": [
        "print(len(load_DrawData.train_loader.dataset))\n",
        "print(len(load_DrawData.val_loader.dataset))\n",
        "\n",
        "#plt.plot(x, np.cos(x), '--');"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "420\n",
            "180\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}