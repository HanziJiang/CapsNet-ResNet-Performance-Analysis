{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "guide big.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiQpTflFkuqi"
      },
      "source": [
        "# Capsule Neural Network (CapsNet) Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDxJ_A_0Gnt9"
      },
      "source": [
        "Implementation of the paper [Dynamic Routing Between Capsules](https://arxiv.org/pdf/1710.09829.pdf) by Sara Sabour, Nicholas Frosst, and Geoffrey E. Hinton. Used [jindongwang/Pytorch-CapsuleNet](https://github.com/jindongwang/Pytorch-CapsuleNet) and [laubonghaudoi/CapsNet_guide_PyTorch](https://github.com/laubonghaudoi/CapsNet_guide_PyTorch) to clarify some confusions, and borrowed some code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pkx4McDDItG"
      },
      "source": [
        "## Setup PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peSdN_P8CElk",
        "outputId": "cd544734-f210-4180-9fa5-94a11326a2a0"
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install matplotlib\n",
        "!pip install import-ipynb\n",
        "!pip install tqdm\n",
        "!pip install pytorch_extras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp37-none-any.whl size=2976 sha256=5ff862f493a5537c606054e1e8a58a777dc48971fa2816a37080d5eeb8aa4603\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Collecting pytorch_extras\n",
            "  Downloading https://files.pythonhosted.org/packages/66/79/42d7d9a78c27eb897b14790c9759dd9a991f67bc987e9e137527a68db9dc/pytorch-extras-0.1.3.tar.gz\n",
            "Building wheels for collected packages: pytorch-extras\n",
            "  Building wheel for pytorch-extras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-extras: filename=pytorch_extras-0.1.3-cp37-none-any.whl size=2833 sha256=45a3160f3f11d506c85ce9100508fc1d9465c7e364d970a23da45fa6d1bf9f60\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/7c/5a/f27d4088adfe722cb280d523a1ed9eeb33be11b8d3a653292a\n",
            "Successfully built pytorch-extras\n",
            "Installing collected packages: pytorch-extras\n",
            "Successfully installed pytorch-extras-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMdBumXa75tw",
        "outputId": "73a5c3f6-f2fc-41a5-8243-a58fbd791602"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"mnt\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at mnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlYHtO737_dA",
        "outputId": "1a99bba1-8e10-4187-be0a-b09a25a30c43"
      },
      "source": [
        "%cd \"mnt/My Drive\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mnt/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsZEHMrIEVz6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de55323e-e24e-48b8-ce58-2fc220519190"
      },
      "source": [
        "import torch\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_extras\n",
        "import torch.nn as nn\n",
        "import torchvision.utils as tv_utils\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import import_ipynb\n",
        "import load_DrawData_with_transform as loader\n",
        "import numpy as np\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "# %mkdir -p /content/project/\n",
        "# %cd /content/project/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from load_DrawData_with_transform.ipynb\n",
            "Collecting ndjson\n",
            "  Downloading https://files.pythonhosted.org/packages/70/c9/04ba0056011ba96a58163ebfd666d8385300bd12da1afe661a5a147758d7/ndjson-0.3.1-py2.py3-none-any.whl\n",
            "Installing collected packages: ndjson\n",
            "Successfully installed ndjson-0.3.1\n",
            "Collecting cairocffi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ca/0bffed5116d21251469df200448667e90acaa5131edea869b44a3fbc73d0/cairocffi-1.2.0.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.20)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.2.0-cp37-none-any.whl size=89548 sha256=e11094f2e2c9595c1fb4c74dd7c36bf6f1323b67eaf77e2cbcac9d38bc628714\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/76/48/f1effadceea83b32e7d957dd0f92db4db8b537d7b72b4ef374\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.2.0\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "6000\n",
            "4000\n",
            "total training samples: 6000\n",
            "total validatoin samples: 2000\n",
            "total test samples: 2000\n",
            "mkdir: cannot create directory ‘quickDrawData’: File exists\n",
            "gs://quickdraw_dataset/full/simplified/triangle.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/triangle.ndjson...\n",
            "\\ [1/1 files][ 30.5 MiB/ 30.5 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/30.5 MiB.                                     \n",
            "gs://quickdraw_dataset/full/simplified/square.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/square.ndjson...\n",
            "\\ [1/1 files][ 32.0 MiB/ 32.0 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/32.0 MiB.                                     \n",
            "adding from:  triangle\n",
            "adding from:  square\n",
            "building  train  dataset\n",
            "adding from:  triangle\n",
            "adding from:  square\n",
            "building  val  dataset\n",
            "adding from:  triangle\n",
            "adding from:  square\n",
            "building test dataset\n",
            "adding from:  triangle\n",
            "adding from:  square\n",
            "building test dataset\n",
            "adding from:  triangle\n",
            "adding from:  square\n",
            "building test dataset\n",
            "2000\n",
            "2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 1.]\n",
            "triangle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 1.]\n",
            "triangle\n",
            "2000\n",
            "2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 1.]\n",
            "triangle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 1.]\n",
            "triangle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcYm7y8rECqg"
      },
      "source": [
        "## CapsNet Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdGH3V4jJPmQ"
      },
      "source": [
        "class PrimaryCapsules(nn.Module):\n",
        "    '''\n",
        "    The `PrimaryCaps` layer consists of 32 capsule units. Each unit takes\n",
        "    the output of the `Conv1` layer, which is a `[256, 20, 20]` feature\n",
        "    tensor (omitting `batch_size`), and performs a 2D convolution with 8\n",
        "    output channels, kernel size 9 and stride 2, thus outputing a [8, 6, 6]\n",
        "    tensor. In other words, you can see these 32 capsules as 32 paralleled 2D\n",
        "    convolutional layers. Then we concatenate these 32 capsules' outputs and\n",
        "    flatten them into a tensor of size `[1152, 8]`, representing 1152 8D\n",
        "    vectors, and send it to the next layer `DigitCaps`.\n",
        "    As indicated in Section 4, Page 4 in the paper, *One can see PrimaryCaps\n",
        "    as a Convolution layer with Eq.1 as its block non-linearity.*, outputs of\n",
        "    the `PrimaryCaps` layer are squashed before being passed to the next layer.\n",
        "    Reference: Section 4, Fig. 1\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        We build 8 capsule units in the `PrimaryCaps` layer, each can be\n",
        "        seen as a 2D convolution layer.\n",
        "        '''\n",
        "        super(PrimaryCapsules, self).__init__()\n",
        "\n",
        "        self.capsules = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=256,\n",
        "                      out_channels=8,\n",
        "                      kernel_size=9,\n",
        "                      stride=2)\n",
        "            for i in range(32)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Each capsule outputs a [batch_size, 8, 6, 6] tensor, we need to\n",
        "        flatten and concatenate them into a [batch_size, 8, 6*6, 32] size\n",
        "        tensor and flatten and transpose into `u` [batch_size, 1152, 8], \n",
        "        where each [batch_size, 1152, 1] size tensor is the `u_i` in Eq.2. \n",
        "        #### Dimension transformation in this layer(ignoring `batch_size`):\n",
        "        [256, 20, 20] --> [8, 6, 6] x 32 capsules --> [1152, 8]\n",
        "        Note: `u_i` is one [1, 8] in the final [1152, 8] output, thus there are\n",
        "        1152 `u_i`s.\n",
        "        '''\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        u = []\n",
        "        for i in range(32):\n",
        "            # Input: [batch_size, 256, 20, 20]\n",
        "            assert x.data.size() == torch.Size([batch_size, 256, 20, 20]), x.data.size()\n",
        "\n",
        "            u_i = self.capsules[i](x)\n",
        "            assert u_i.size() == torch.Size([batch_size, 8, 6, 6])\n",
        "            # u_i: [batch_size, 8, 6, 6]\n",
        "            u_i = u_i.view(batch_size, 8, -1, 1)\n",
        "            # u_i: [batch_size, 8, 36]\n",
        "            u.append(u_i)\n",
        "\n",
        "        # u: [batch_size, 8, 36, 1] x 32\n",
        "        u = torch.cat(u, dim=3)\n",
        "        # u: [batch_size, 8, 36, 32]\n",
        "        u = u.view(batch_size, 8, -1)\n",
        "        # u: [batch_size, 8, 1152]\n",
        "        u = torch.transpose(u, 1, 2)\n",
        "        # u: [batch_size, 1152, 8]\n",
        "        assert u.data.size() == torch.Size([batch_size, 1152, 8])\n",
        "\n",
        "        # Squash before output\n",
        "        u_squashed = self.squash(u)\n",
        "\n",
        "        return u_squashed\n",
        "\n",
        "    def squash(self, u):\n",
        "        '''\n",
        "        Args:\n",
        "            `u`: [batch_size, 1152, 8]\n",
        "        Return:\n",
        "            `u_squashed`: [batch_size, 1152, 8]\n",
        "        In CapsNet, we use the squash function after the output of both \n",
        "        capsule layers. Squash functions can be seen as activating functions\n",
        "        like sigmoid, but for capsule layers rather than traditional fully\n",
        "        connected layers, as they squash vectors instead of scalars.\n",
        "        v_j = (norm(s_j) ^ 2 / (1 + norm(s_j) ^ 2)) * (s_j / norm(s_j))\n",
        "        Reference: Eq.1 in Section 2.\n",
        "        '''\n",
        "        batch_size = u.size(0)\n",
        "\n",
        "        # u: [batch_size, 1152, 8]\n",
        "        square = u ** 2\n",
        "\n",
        "        # square_sum for u: [batch_size, 1152]\n",
        "        square_sum = torch.sum(square, dim=2)\n",
        "\n",
        "        # norm for u: [batch_size, 1152]\n",
        "        norm = torch.sqrt(square_sum)\n",
        "\n",
        "        # factor for u: [batch_size, 1152]\n",
        "        factor = norm ** 2 / (norm * (1 + norm ** 2))\n",
        "\n",
        "        # u_squashed: [batch_size, 1152, 8]\n",
        "        u_squashed = factor.unsqueeze(2) * u\n",
        "        assert u_squashed.size() == torch.Size([batch_size, 1152, 8])\n",
        "\n",
        "        return u_squashed"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz1tFdzkaHyP"
      },
      "source": [
        "class DoodleCapsules(nn.Module):\n",
        "    '''\n",
        "    The `DigitCaps` layer consists of 10 16D capsules. Compared to the traditional\n",
        "    scalar output neurons in fully connected networks(FCN), the `DigitCaps` layer\n",
        "    can be seen as an FCN with ten 16-dimensional output neurons, which we call\n",
        "    these neurons \"capsules\".\n",
        "    In this layer, we take the input `[1152, 8]` tensor `u` as 1152 [8,] vectors\n",
        "    `u_i`, each `u_i` is a 8D output of the capsules from `PrimaryCaps` (see Eq.2\n",
        "    in Section 2, Page 2) and sent to the 10 capsules. For each capsule, the tensor\n",
        "    is first transformed by `W_ij`s into [1152, 16] size. Then we perform the Dynamic\n",
        "    Routing algorithm to get the output `v_j` of size [16,]. As there are 10 capsules,\n",
        "    the final output is [16, 10] size.\n",
        "    #### Dimension transformation in this layer(ignoring `batch_size`):\n",
        "    [1152, 8] --> [1152, 16] --> [1, 16] x 10 capsules --> [10, 16] output\n",
        "    Note that in our codes we have vectorized these computations, so the dimensions\n",
        "    above are just for understanding, actual dimensions of tensors are different.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        '''\n",
        "        There is only one parameter in this layer, `W` [1, 1152, 10, 16, 8], where\n",
        "        every [8, 16] is a weight matrix W_ij in Eq.2, that is, there are 11520\n",
        "        `W_ij`s in total.\n",
        "        The the coupling coefficients `b` [64, 1152, 10, 1] is a temporary variable which\n",
        "        does NOT belong to the layer's parameters. In other words, `b` is not updated\n",
        "        by gradient back-propagations. Instead, we update `b` by Dynamic Routing\n",
        "        in every forward propagation. See the docstring of `self.forward` for details.\n",
        "        '''\n",
        "        super(DoodleCapsules, self).__init__()\n",
        "        self.opt = opt\n",
        "\n",
        "        self.W = nn.Parameter(torch.randn(1, 1152, opt.n_classes, 8, 16))\n",
        "\n",
        "    def forward(self, u):\n",
        "        '''\n",
        "        Args:\n",
        "            `u`: [batch_size, 1152, 8]\n",
        "        Return:\n",
        "            `v`: [batch_size, 10, 16]\n",
        "        In this layer, we vectorize our computations by calling `W` and using\n",
        "        `torch.matmul()`. Thus the full computaion steps are as follows.\n",
        "            1. Expand `W` into batches and compute `u_hat` (Eq.2)\n",
        "            2. Line 2: Initialize `b` into zeros\n",
        "            3. Line 3: Start Routing for `r` iterations:\n",
        "                1. Line 4: c = softmax(b)\n",
        "                2. Line 5: s = sum(c * u_hat)\n",
        "                3. Line 6: v = squash(s)\n",
        "                4. Line 7: b += u_hat * v\n",
        "        The coupling coefficients `b` can be seen as a kind of attention matrix\n",
        "        in the attentional sequence-to-sequence networks, which is widely used in\n",
        "        Neural Machine Translation systems. For tutorials on  attentional seq2seq\n",
        "        models, see https://arxiv.org/abs/1703.01619 or\n",
        "        http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "        Reference: Section 2, Procedure 1\n",
        "        '''\n",
        "        batch_size = u.size(0)\n",
        "\n",
        "        # First, we need to expand the dimensions of `W` and `u` to compute `u_hat`\n",
        "        assert u.size() == torch.Size([batch_size, 1152, 8])\n",
        "        # u: [batch_size, 1152, 1, 1, 8]\n",
        "        u = torch.unsqueeze(u, dim=2)\n",
        "        u = torch.unsqueeze(u, dim=2)\n",
        "        # Now we compute u_hat in Eq.2\n",
        "        # u_hat: [batch_size, 1152, 10, 16]\n",
        "        u_hat = torch.matmul(u, self.W).squeeze()\n",
        "\n",
        "        # Line 2: Initialize b into zeros\n",
        "        # b: [batch_size, 1152, 10, 1]\n",
        "        b = Variable(torch.zeros(batch_size, 1152, opt.n_classes, 1))\n",
        "        if self.opt.use_cuda & torch.cuda.is_available():\n",
        "            b = b.cuda()\n",
        "\n",
        "        # Start Routing\n",
        "        for r in range(self.opt.r):\n",
        "            # Line 4: c_i = softmax(b_i)\n",
        "            # c: [b, 1152, 10, 1]\n",
        "            c = F.softmax(b, dim=2)\n",
        "            assert c.size() == torch.Size([batch_size, 1152, opt.n_classes, 1])\n",
        "\n",
        "            # Line 5: s_j = sum_i(c_ij * u_hat_j|i)\n",
        "            # u_hat: [batch_size, 1152, 10, 16]\n",
        "            # s: [batch_size, 10, 16]\n",
        "            s = torch.sum(u_hat * c, dim=1)\n",
        "\n",
        "            # Line 6: v_j = squash(s_j)\n",
        "            # v: [batch_size, 10, 16]\n",
        "            v = self.squash(s)\n",
        "            assert v.size() == torch.Size([batch_size, opt.n_classes, 16])\n",
        "\n",
        "            # Line 7: b_ij += u_hat * v_j\n",
        "            # u_hat: [batch_size, 1152, 10, 16]\n",
        "            # v: [batch_size, 10, 16]\n",
        "            # a: [batch_size, 10, 1152, 16]\n",
        "            a = u_hat * v.unsqueeze(1)\n",
        "            # b: [batch_size, 1152, 10, 1]\n",
        "            b = b + torch.sum(a, dim=3, keepdim=True)\n",
        "\n",
        "        return v\n",
        "\n",
        "    def squash(self, s):\n",
        "        '''\n",
        "        Args:\n",
        "            `s`: [batch_size, 10, 16]\n",
        "        v_j = (norm(s_j) ^ 2 / (1 + norm(s_j) ^ 2)) * (s_j / norm(s_j))\n",
        "        Reference: Eq.1 in Section 2.\n",
        "        '''\n",
        "        batch_size = s.size(0)\n",
        "\n",
        "        # s: [batch_size, 10, 16]\n",
        "        square = s ** 2\n",
        "\n",
        "        # square_sum for v: [batch_size, 10]\n",
        "        square_sum = torch.sum(square, dim=2)\n",
        "\n",
        "        # norm for v: [batch_size, 10]\n",
        "        norm = torch.sqrt(square_sum)\n",
        "\n",
        "        # factor for v: [batch_size, 10]\n",
        "        factor = norm ** 2 / (norm * (1 + norm ** 2))\n",
        "\n",
        "        # v: [batch_size, 10, 16]\n",
        "        v = factor.unsqueeze(2) * s\n",
        "        assert v.size() == torch.Size([batch_size, opt.n_classes, 16])\n",
        "\n",
        "        return v"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-k05aXUmDs8"
      },
      "source": [
        "class DoodleDecoder(nn.Module):\n",
        "    '''\n",
        "    The decoder network consists of 3 fully connected layers. For each\n",
        "    [10, 16] output, we mask out the incorrect predictions, and send\n",
        "    the [16,] vector to the decoder network to reconstruct a [784,] size\n",
        "    image.\n",
        "    Reference: Section 4.1, Fig. 2\n",
        "    '''\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        '''\n",
        "        The decoder network consists of 3 fully connected layers, with\n",
        "        512, 1024, 784 neurons each.\n",
        "        '''\n",
        "        super(DoodleDecoder, self).__init__()\n",
        "        self.opt = opt\n",
        "\n",
        "        self.fc1 = nn.Linear(16, 512)\n",
        "        self.fc2 = nn.Linear(512, 1024)\n",
        "        self.fc3 = nn.Linear(1024, opt.image_size*opt.image_size)\n",
        "\n",
        "    def forward(self, v, target):\n",
        "        '''\n",
        "        Args:\n",
        "            `v`: [batch_size, 10, 16]\n",
        "            `target`: [batch_size, 10]\n",
        "        Return:\n",
        "            `reconstruction`: [batch_size, 784]\n",
        "        We send the outputs of the `DigitCaps` layer, which is a\n",
        "        [batch_size, 10, 16] size tensor into the decoder network, and\n",
        "        reconstruct a [batch_size, 784] size tensor representing the image.\n",
        "        '''\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        target = target.type(torch.FloatTensor)\n",
        "        # mask: [batch_size, 10, 16]\n",
        "        mask = torch.stack([target for i in range(16)], dim=2)\n",
        "        assert mask.size() == torch.Size([batch_size, opt.n_classes, 16])\n",
        "        if self.opt.use_cuda & torch.cuda.is_available():\n",
        "            mask = mask.cuda()\n",
        "\n",
        "        # v: [bath_size, 10, 16]\n",
        "        v_masked = mask * v\n",
        "        v_masked = torch.sum(v_masked, dim=1)\n",
        "        assert v_masked.size() == torch.Size([batch_size, 16])\n",
        "\n",
        "        # Forward\n",
        "        v = F.relu(self.fc1(v_masked))\n",
        "        v = F.relu(self.fc2(v))\n",
        "        reconstruction = torch.sigmoid(self.fc3(v))\n",
        "\n",
        "        assert reconstruction.size() == torch.Size([batch_size, opt.image_size*opt.image_size])\n",
        "        return reconstruction"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH6pouLtXQnx"
      },
      "source": [
        "class CapsuleNetwork(nn.Module):\n",
        "    '''Consists of a ReLU Convolution layer, a PrimaryCapsules layer, a DoodleCapsules\n",
        "    layer, and a Decoder layer. Section 4 of the paper.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        super(CapsuleNetwork, self).__init__()\n",
        "        self.opt = opt\n",
        "\n",
        "        self.Conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=21)\n",
        "        self.PrimaryCaps = PrimaryCapsules()\n",
        "        self.DigitCaps = DoodleCapsules(opt)\n",
        "\n",
        "        self.Decoder = DoodleDecoder(opt)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Args:\n",
        "            `x`: [batch_size, 1, 28, 28] MNIST samples\n",
        "        \n",
        "        Return:\n",
        "            `v`: [batch_size, 10, 16] CapsNet outputs, 16D prediction vectors of\n",
        "                10 digit capsules\n",
        "        The dimension transformation procedure of an input tensor in each layer:\n",
        "            0. Input: [batch_size, 1, 28, 28] -->\n",
        "            1. `Conv1` --> [batch_size, 256, 20, 20] --> \n",
        "            2. `PrimaryCaps` --> [batch_size, 8, 6, 6] x 32 capsules --> \n",
        "            3. Flatten, concatenate, squash --> [batch_size, 1152, 8] -->\n",
        "            4. `W_ij`s and `DigitCaps` --> [batch_size, 16, 10] -->\n",
        "            5. Length of 10 capsules --> [batch_size, 10] output probabilities\n",
        "        '''\n",
        "        # Input: [batch_size, 1, 28, 28]\n",
        "        x = x.view(-1, 1, opt.image_size, opt.image_size)\n",
        "        x = F.relu(self.Conv1(x))\n",
        "        # PrimaryCaps input: [batch_size, 256, 20, 20]\n",
        "        u = self.PrimaryCaps(x)\n",
        "        # PrimaryCaps output u: [batch_size, 1152, 8]\n",
        "        v = self.DigitCaps(u)\n",
        "        # DigitCaps output v: [batsh_size, 10, 16]\n",
        "        return v\n",
        "\n",
        "    def marginal_loss(self, v, target, l=0.5):\n",
        "        '''\n",
        "        Args:\n",
        "            `v`: [batch_size, 10, 16]\n",
        "            `target`: [batch_size, 10]\n",
        "            `l`: Scalar, lambda for down-weighing the loss for absent digit classes\n",
        "        Return:\n",
        "            `marginal_loss`: Scalar\n",
        "        \n",
        "        L_c = T_c * max(0, m_plus - norm(v_c)) ^ 2 + lambda * (1 - T_c) * max(0, norm(v_c) - m_minus) ^2\n",
        "        \n",
        "        Reference: Eq.4 in Section 3.\n",
        "        '''\n",
        "        batch_size = v.size(0)\n",
        "\n",
        "        square = v ** 2\n",
        "        square_sum = torch.sum(square, dim=2)\n",
        "        # norm: [batch_size, 10]\n",
        "        norm = torch.sqrt(square_sum)\n",
        "        assert norm.size() == torch.Size([batch_size, 2])\n",
        "\n",
        "        # The two T_c in Eq.4\n",
        "        T_c = target.type(torch.FloatTensor)\n",
        "        zeros = Variable(torch.zeros(norm.size()))\n",
        "        # Use GPU if available\n",
        "        if self.opt.use_cuda & torch.cuda.is_available():\n",
        "            zeros = zeros.cuda()\n",
        "            T_c = T_c.cuda()\n",
        "\n",
        "        # Eq.4\n",
        "        marginal_loss = T_c * (torch.max(zeros, 0.9 - norm) ** 2) + \\\n",
        "            (1 - T_c) * l * (torch.max(zeros, norm - 0.1) ** 2)\n",
        "        marginal_loss = torch.sum(marginal_loss)\n",
        "\n",
        "        return marginal_loss\n",
        "\n",
        "    def reconstruction_loss(self, reconstruction, image):\n",
        "        '''\n",
        "        Args:\n",
        "            `reconstruction`: [batch_size, 784] Decoder outputs of images\n",
        "            `image`: [batch_size, 1, 28, 28] MNIST samples\n",
        "        Return:\n",
        "            `reconstruction_loss`: Scalar Variable\n",
        "        The reconstruction loss is measured by a squared differences\n",
        "        between the reconstruction and the original image. \n",
        "        Reference: Section 4.1\n",
        "        '''\n",
        "        batch_size = image.size(0)\n",
        "        # image: [batch_size, 784]\n",
        "        image = image.view(batch_size, -1)\n",
        "        assert image.size() == (batch_size, opt.image_size*opt.image_size)\n",
        "        \n",
        "        # Scalar Variable\n",
        "        reconstruction_loss = torch.sum((reconstruction - image) ** 2)\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def loss(self, v, image, target):\n",
        "        '''\n",
        "        Args:\n",
        "            `v`: [batch_size, 10, 16] CapsNet outputs\n",
        "            `target`: [batch_size, 10] One-hot MNIST labels\n",
        "            `image`: [batch_size, 1, 28, 28] MNIST samples\n",
        "        Return:\n",
        "            `L`: Scalar Variable, total loss\n",
        "            `marginal_loss`: Scalar Variable\n",
        "            `reconstruction_loss`: Scalar Variable\n",
        "        The reconstruction loss is scaled down by 5e-4, serving as a\n",
        "        regularization method.\n",
        "        Reference: Section 4.1\n",
        "        '''\n",
        "        batch_size = image.size(0)\n",
        "\n",
        "        marginal_loss = self.marginal_loss(v, target)\n",
        "\n",
        "        # Get reconstructions from the decoder network\n",
        "        reconstruction = self.Decoder(v, target)\n",
        "        reconstruction_loss = self.reconstruction_loss(reconstruction, image)\n",
        "\n",
        "        # Scalar Variable\n",
        "        loss = (marginal_loss + 0.0005 * reconstruction_loss) / batch_size\n",
        "\n",
        "        return loss, marginal_loss / batch_size, reconstruction_loss / batch_size"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKPXAofhnYhK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCM0T0_1d5W"
      },
      "source": [
        "def evaluate(opt, valid_loader, model, type_data, plot=False):\n",
        "    sum_loss = 0\n",
        "    sum_marginal_loss = 0\n",
        "    sum_reconstruction_loss = 0\n",
        "    correct = 0\n",
        "    num_sample = len(valid_loader.dataset)\n",
        "    num_batch = len(valid_loader)\n",
        "\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "        data = data.to(torch.float32)\n",
        "        target = target.to(torch.int64)\n",
        "        batch_size = data.size(0)\n",
        "        assert target.size() == torch.Size([batch_size, opt.n_classes])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            data, target = Variable(data), Variable(target)\n",
        "        if opt.use_cuda & torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output = model(data)  # (batch_size, n_classes, 16)\n",
        "        loss, marginal_loss, reconstruction_loss = model.loss(output, data, target)\n",
        "        sum_loss += loss.item()\n",
        "        sum_marginal_loss += marginal_loss.item()\n",
        "        sum_reconstruction_loss += reconstruction_loss.item()\n",
        "\n",
        "        norms = torch.sqrt(torch.sum(output**2, dim=2))  # (batch_size, n_classes)\n",
        "        pred = norms.data.max(1, keepdim=True)[1].type(torch.LongTensor)  # (batch_size, 1)\n",
        "        label = target.max(1, keepdim=True)[1].type(torch.LongTensor)  # (batch_size, 1)\n",
        "        correct += pred.eq(label.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    if plot:\n",
        "        recons = model.Decoder(output, target)\n",
        "        recons = recons.view(batch_size, opt.image_size, opt.image_size)\n",
        "        recons = recons[0].cpu()\n",
        "        plt.imshow(recons.detach(), cmap = \"gray\")\n",
        "\n",
        "    sum_loss /= num_batch\n",
        "    sum_marginal_loss /= num_batch\n",
        "    sum_reconstruction_loss /= num_batch\n",
        "    print('{} loss: {:.4f}   Marginal loss: {:.4f}   Reconstruction loss: {:.4f}'.format(\n",
        "        type_data, sum_loss, sum_marginal_loss, sum_reconstruction_loss))\n",
        "    print('Accuracy: {}/{} {:.4f}'.format(correct, num_sample,\n",
        "        correct / num_sample))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcoOvQfb1bVn"
      },
      "source": [
        "def train(opt, train_loader, valid_loader, model):\n",
        "    num_sample = len(train_loader.dataset)\n",
        "    num_batches = len(train_loader)\n",
        "    train_loss_list = []\n",
        "    loss_val = 0.\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, opt.gamma)\n",
        "    model.train()\n",
        "    evaluate(opt, train_loader, model, 'initial TRAIN', False) \n",
        "    evaluate(opt, valid_loader, model, 'initial VALID', False)\n",
        "    for epoch in range(opt.epochs):\n",
        "    \n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            data = data.to(torch.float32)\n",
        "            \n",
        "            batch_size = data.size(0)\n",
        "            target = target.to(torch.int64)\n",
        "            assert target.size() == torch.Size([batch_size, opt.n_classes])\n",
        "\n",
        "            # Use GPU if available\n",
        "            with torch.no_grad():\n",
        "                data, target = Variable(data), Variable(target)\n",
        "            if opt.use_cuda & torch.cuda.is_available():\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "            output = model(data)\n",
        "            loss, marginal_loss, reconstruction_loss = model.loss(output, data, target)\n",
        "            loss_val = loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch % 5 == 0: \n",
        "            train_loss_list.append(loss_val)\n",
        "        if epoch % 1 == 0:\n",
        "            print('\\nEpoch: {}'.format(epoch))\n",
        "            print('Learning rate: {:.2e}'.format(scheduler.get_last_lr()[0]))\n",
        "            evaluate(opt, train_loader, model, 'TRAIN', False) \n",
        "            evaluate(opt, valid_loader, model, 'VALID', False)\n",
        "\n",
        "        # torch.save({\n",
        "        #     'epoch': epoch,\n",
        "        #     'model_state_dict': model.state_dict(),\n",
        "        #     'optimizer_state_dict': optimizer.state_dict(),\n",
        "        #     'loss': loss,\n",
        "        #     }, 'guide_big_model.pt')\n",
        "        \n",
        "        scheduler.step()\n",
        "    fig = plt.figure()\n",
        "    plt.plot([i for i in range(len(train_loss_list))], train_loss_list, '-')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Holn-KGHnvZH"
      },
      "source": [
        "def get_opts():\n",
        "    parser = argparse.ArgumentParser(description='CapsuleNetwork')\n",
        "    parser.add_argument('-image_size', type=int, default=40)\n",
        "    parser.add_argument('-batch_size', type=int, default=32)\n",
        "    parser.add_argument('-lr', type=float, default=1e-4)\n",
        "    parser.add_argument('-epochs', type=int, default=120)\n",
        "    parser.add_argument('-n_classes', type=int, default=2)\n",
        "    parser.add_argument('-use_cuda', default=True)\n",
        "    parser.add_argument('-gamma', type=float, default=0.8)\n",
        "    parser.add_argument('-r', type=int, default=4)\n",
        "    opt, _ = parser.parse_known_args()\n",
        "    return opt"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4zXW1i3p1uq8",
        "outputId": "02a05029-cfa4-4ea5-a35f-797635514b2d"
      },
      "source": [
        "opt = get_opts()\n",
        "\n",
        "model = CapsuleNetwork(opt)\n",
        "if opt.use_cuda & torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "train_loader = loader.train_loader\n",
        "valid_loader = loader.val_loader\n",
        "\n",
        "train(opt, train_loader, valid_loader, model)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial TRAIN loss: 2723.6584   Marginal loss: 0.4050   Reconstruction loss: 5446506.4388\n",
            "Accuracy: 3679/6000 0.6132\n",
            "initial VALID loss: 2709.1634   Marginal loss: 0.4050   Reconstruction loss: 5417516.3968\n",
            "Accuracy: 1247/2000 0.6235\n",
            "\n",
            "Epoch: 0\n",
            "Learning rate: 1.00e-04\n",
            "TRAIN loss: 2710.2201   Marginal loss: 0.4050   Reconstruction loss: 5419629.9202\n",
            "Accuracy: 5575/6000 0.9292\n",
            "VALID loss: 2695.6524   Marginal loss: 0.4050   Reconstruction loss: 5390494.5079\n",
            "Accuracy: 1875/2000 0.9375\n",
            "\n",
            "Epoch: 1\n",
            "Learning rate: 8.00e-05\n",
            "TRAIN loss: 2709.9167   Marginal loss: 0.4050   Reconstruction loss: 5419023.1250\n",
            "Accuracy: 5572/6000 0.9287\n",
            "VALID loss: 2695.5980   Marginal loss: 0.4050   Reconstruction loss: 5390385.6508\n",
            "Accuracy: 1880/2000 0.9400\n",
            "\n",
            "Epoch: 2\n",
            "Learning rate: 6.40e-05\n",
            "TRAIN loss: 2710.0485   Marginal loss: 0.4050   Reconstruction loss: 5419286.5957\n",
            "Accuracy: 5583/6000 0.9305\n",
            "VALID loss: 2695.5883   Marginal loss: 0.4050   Reconstruction loss: 5390366.2698\n",
            "Accuracy: 1885/2000 0.9425\n",
            "\n",
            "Epoch: 3\n",
            "Learning rate: 5.12e-05\n",
            "TRAIN loss: 2709.6744   Marginal loss: 0.4050   Reconstruction loss: 5418538.4761\n",
            "Accuracy: 5595/6000 0.9325\n",
            "VALID loss: 2695.5859   Marginal loss: 0.4050   Reconstruction loss: 5390361.3810\n",
            "Accuracy: 1888/2000 0.9440\n",
            "\n",
            "Epoch: 4\n",
            "Learning rate: 4.10e-05\n",
            "TRAIN loss: 2709.7510   Marginal loss: 0.4050   Reconstruction loss: 5418691.6117\n",
            "Accuracy: 5632/6000 0.9387\n",
            "VALID loss: 2695.5849   Marginal loss: 0.4050   Reconstruction loss: 5390359.4444\n",
            "Accuracy: 1887/2000 0.9435\n",
            "\n",
            "Epoch: 5\n",
            "Learning rate: 3.28e-05\n",
            "TRAIN loss: 2710.1049   Marginal loss: 0.4050   Reconstruction loss: 5419399.4734\n",
            "Accuracy: 5630/6000 0.9383\n",
            "VALID loss: 2695.5844   Marginal loss: 0.4050   Reconstruction loss: 5390358.5476\n",
            "Accuracy: 1894/2000 0.9470\n",
            "\n",
            "Epoch: 6\n",
            "Learning rate: 2.62e-05\n",
            "TRAIN loss: 2709.5740   Marginal loss: 0.4050   Reconstruction loss: 5418337.6516\n",
            "Accuracy: 5632/6000 0.9387\n",
            "VALID loss: 2695.5841   Marginal loss: 0.4050   Reconstruction loss: 5390357.9127\n",
            "Accuracy: 1901/2000 0.9505\n",
            "\n",
            "Epoch: 7\n",
            "Learning rate: 2.10e-05\n",
            "TRAIN loss: 2710.0506   Marginal loss: 0.4050   Reconstruction loss: 5419290.7793\n",
            "Accuracy: 5632/6000 0.9387\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.5476\n",
            "Accuracy: 1894/2000 0.9470\n",
            "\n",
            "Epoch: 8\n",
            "Learning rate: 1.68e-05\n",
            "TRAIN loss: 2710.0572   Marginal loss: 0.4050   Reconstruction loss: 5419304.1702\n",
            "Accuracy: 5622/6000 0.9370\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4683\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 9\n",
            "Learning rate: 1.34e-05\n",
            "TRAIN loss: 2709.9166   Marginal loss: 0.4050   Reconstruction loss: 5419022.8617\n",
            "Accuracy: 5649/6000 0.9415\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4524\n",
            "Accuracy: 1894/2000 0.9470\n",
            "\n",
            "Epoch: 10\n",
            "Learning rate: 1.07e-05\n",
            "TRAIN loss: 2710.0261   Marginal loss: 0.4050   Reconstruction loss: 5419241.9149\n",
            "Accuracy: 5646/6000 0.9410\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4286\n",
            "Accuracy: 1897/2000 0.9485\n",
            "\n",
            "Epoch: 11\n",
            "Learning rate: 8.59e-06\n",
            "TRAIN loss: 2709.7524   Marginal loss: 0.4050   Reconstruction loss: 5418694.5106\n",
            "Accuracy: 5656/6000 0.9427\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4365\n",
            "Accuracy: 1904/2000 0.9520\n",
            "\n",
            "Epoch: 12\n",
            "Learning rate: 6.87e-06\n",
            "TRAIN loss: 2709.6069   Marginal loss: 0.4050   Reconstruction loss: 5418403.4362\n",
            "Accuracy: 5637/6000 0.9395\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4206\n",
            "Accuracy: 1899/2000 0.9495\n",
            "\n",
            "Epoch: 13\n",
            "Learning rate: 5.50e-06\n",
            "TRAIN loss: 2709.9080   Marginal loss: 0.4050   Reconstruction loss: 5419005.7261\n",
            "Accuracy: 5647/6000 0.9412\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4286\n",
            "Accuracy: 1897/2000 0.9485\n",
            "\n",
            "Epoch: 14\n",
            "Learning rate: 4.40e-06\n",
            "TRAIN loss: 2709.9558   Marginal loss: 0.4050   Reconstruction loss: 5419101.3191\n",
            "Accuracy: 5640/6000 0.9400\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4206\n",
            "Accuracy: 1894/2000 0.9470\n",
            "\n",
            "Epoch: 15\n",
            "Learning rate: 3.52e-06\n",
            "TRAIN loss: 2709.7070   Marginal loss: 0.4050   Reconstruction loss: 5418603.7287\n",
            "Accuracy: 5640/6000 0.9400\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4127\n",
            "Accuracy: 1894/2000 0.9470\n",
            "\n",
            "Epoch: 16\n",
            "Learning rate: 2.81e-06\n",
            "TRAIN loss: 2710.1522   Marginal loss: 0.4050   Reconstruction loss: 5419494.0532\n",
            "Accuracy: 5661/6000 0.9435\n",
            "VALID loss: 2695.5839   Marginal loss: 0.4050   Reconstruction loss: 5390357.4048\n",
            "Accuracy: 1899/2000 0.9495\n",
            "\n",
            "Epoch: 17\n",
            "Learning rate: 2.25e-06\n",
            "TRAIN loss: 2709.5376   Marginal loss: 0.4050   Reconstruction loss: 5418264.8830\n",
            "Accuracy: 5642/6000 0.9403\n",
            "VALID loss: 2695.5838   Marginal loss: 0.4050   Reconstruction loss: 5390357.3413\n",
            "Accuracy: 1900/2000 0.9500\n",
            "\n",
            "Epoch: 18\n",
            "Learning rate: 1.80e-06\n",
            "TRAIN loss: 2709.9521   Marginal loss: 0.4050   Reconstruction loss: 5419093.9521\n",
            "Accuracy: 5655/6000 0.9425\n",
            "VALID loss: 2695.5838   Marginal loss: 0.4050   Reconstruction loss: 5390357.2937\n",
            "Accuracy: 1898/2000 0.9490\n",
            "\n",
            "Epoch: 19\n",
            "Learning rate: 1.44e-06\n",
            "TRAIN loss: 2710.0119   Marginal loss: 0.4050   Reconstruction loss: 5419213.4654\n",
            "Accuracy: 5656/6000 0.9427\n",
            "VALID loss: 2695.5838   Marginal loss: 0.4050   Reconstruction loss: 5390357.2619\n",
            "Accuracy: 1900/2000 0.9500\n",
            "\n",
            "Epoch: 20\n",
            "Learning rate: 1.15e-06\n",
            "TRAIN loss: 2709.9328   Marginal loss: 0.4050   Reconstruction loss: 5419055.2766\n",
            "Accuracy: 5652/6000 0.9420\n",
            "VALID loss: 2695.5838   Marginal loss: 0.4050   Reconstruction loss: 5390357.1746\n",
            "Accuracy: 1901/2000 0.9505\n",
            "\n",
            "Epoch: 21\n",
            "Learning rate: 9.22e-07\n",
            "TRAIN loss: 2710.0687   Marginal loss: 0.4050   Reconstruction loss: 5419327.1596\n",
            "Accuracy: 5648/6000 0.9413\n",
            "VALID loss: 2695.5837   Marginal loss: 0.4050   Reconstruction loss: 5390357.0873\n",
            "Accuracy: 1900/2000 0.9500\n",
            "\n",
            "Epoch: 22\n",
            "Learning rate: 7.38e-07\n",
            "TRAIN loss: 2709.9866   Marginal loss: 0.4050   Reconstruction loss: 5419162.8564\n",
            "Accuracy: 5645/6000 0.9408\n",
            "VALID loss: 2695.5837   Marginal loss: 0.4050   Reconstruction loss: 5390357.0794\n",
            "Accuracy: 1902/2000 0.9510\n",
            "\n",
            "Epoch: 23\n",
            "Learning rate: 5.90e-07\n",
            "TRAIN loss: 2709.9747   Marginal loss: 0.4050   Reconstruction loss: 5419139.0771\n",
            "Accuracy: 5647/6000 0.9412\n",
            "VALID loss: 2695.5837   Marginal loss: 0.4050   Reconstruction loss: 5390357.0317\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 24\n",
            "Learning rate: 4.72e-07\n",
            "TRAIN loss: 2709.2905   Marginal loss: 0.4050   Reconstruction loss: 5417770.7420\n",
            "Accuracy: 5645/6000 0.9408\n",
            "VALID loss: 2695.5837   Marginal loss: 0.4050   Reconstruction loss: 5390356.9921\n",
            "Accuracy: 1900/2000 0.9500\n",
            "\n",
            "Epoch: 25\n",
            "Learning rate: 3.78e-07\n",
            "TRAIN loss: 2709.6192   Marginal loss: 0.4050   Reconstruction loss: 5418428.1436\n",
            "Accuracy: 5649/6000 0.9415\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.9127\n",
            "Accuracy: 1899/2000 0.9495\n",
            "\n",
            "Epoch: 26\n",
            "Learning rate: 3.02e-07\n",
            "TRAIN loss: 2709.7680   Marginal loss: 0.4050   Reconstruction loss: 5418725.5824\n",
            "Accuracy: 5649/6000 0.9415\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.8651\n",
            "Accuracy: 1898/2000 0.9490\n",
            "\n",
            "Epoch: 27\n",
            "Learning rate: 2.42e-07\n",
            "TRAIN loss: 2709.5884   Marginal loss: 0.4050   Reconstruction loss: 5418366.5346\n",
            "Accuracy: 5650/6000 0.9417\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.8016\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 28\n",
            "Learning rate: 1.93e-07\n",
            "TRAIN loss: 2709.9902   Marginal loss: 0.4050   Reconstruction loss: 5419169.9920\n",
            "Accuracy: 5646/6000 0.9410\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7937\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 29\n",
            "Learning rate: 1.55e-07\n",
            "TRAIN loss: 2709.8065   Marginal loss: 0.4050   Reconstruction loss: 5418802.6862\n",
            "Accuracy: 5650/6000 0.9417\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7937\n",
            "Accuracy: 1895/2000 0.9475\n",
            "\n",
            "Epoch: 30\n",
            "Learning rate: 1.24e-07\n",
            "TRAIN loss: 2709.8018   Marginal loss: 0.4050   Reconstruction loss: 5418793.2819\n",
            "Accuracy: 5640/6000 0.9400\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7937\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 31\n",
            "Learning rate: 9.90e-08\n",
            "TRAIN loss: 2709.9385   Marginal loss: 0.4050   Reconstruction loss: 5419066.6968\n",
            "Accuracy: 5648/6000 0.9413\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7937\n",
            "Accuracy: 1899/2000 0.9495\n",
            "\n",
            "Epoch: 32\n",
            "Learning rate: 7.92e-08\n",
            "TRAIN loss: 2710.1556   Marginal loss: 0.4050   Reconstruction loss: 5419500.9043\n",
            "Accuracy: 5646/6000 0.9410\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1893/2000 0.9465\n",
            "\n",
            "Epoch: 33\n",
            "Learning rate: 6.34e-08\n",
            "TRAIN loss: 2709.8392   Marginal loss: 0.4050   Reconstruction loss: 5418867.9947\n",
            "Accuracy: 5650/6000 0.9417\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1901/2000 0.9505\n",
            "\n",
            "Epoch: 34\n",
            "Learning rate: 5.07e-08\n",
            "TRAIN loss: 2709.7421   Marginal loss: 0.4050   Reconstruction loss: 5418673.8856\n",
            "Accuracy: 5645/6000 0.9408\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1899/2000 0.9495\n",
            "\n",
            "Epoch: 35\n",
            "Learning rate: 4.06e-08\n",
            "TRAIN loss: 2710.0930   Marginal loss: 0.4050   Reconstruction loss: 5419375.6277\n",
            "Accuracy: 5653/6000 0.9422\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1900/2000 0.9500\n",
            "\n",
            "Epoch: 36\n",
            "Learning rate: 3.25e-08\n",
            "TRAIN loss: 2709.8296   Marginal loss: 0.4050   Reconstruction loss: 5418848.8138\n",
            "Accuracy: 5655/6000 0.9425\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 37\n",
            "Learning rate: 2.60e-08\n",
            "TRAIN loss: 2710.2159   Marginal loss: 0.4050   Reconstruction loss: 5419621.5691\n",
            "Accuracy: 5641/6000 0.9402\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1899/2000 0.9495\n",
            "\n",
            "Epoch: 38\n",
            "Learning rate: 2.08e-08\n",
            "TRAIN loss: 2709.9850   Marginal loss: 0.4050   Reconstruction loss: 5419159.6303\n",
            "Accuracy: 5638/6000 0.9397\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1897/2000 0.9485\n",
            "\n",
            "Epoch: 39\n",
            "Learning rate: 1.66e-08\n",
            "TRAIN loss: 2710.2251   Marginal loss: 0.4050   Reconstruction loss: 5419639.9681\n",
            "Accuracy: 5654/6000 0.9423\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1890/2000 0.9450\n",
            "\n",
            "Epoch: 40\n",
            "Learning rate: 1.33e-08\n",
            "TRAIN loss: 2709.9232   Marginal loss: 0.4050   Reconstruction loss: 5419036.1383\n",
            "Accuracy: 5650/6000 0.9417\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1897/2000 0.9485\n",
            "\n",
            "Epoch: 41\n",
            "Learning rate: 1.06e-08\n",
            "TRAIN loss: 2709.5721   Marginal loss: 0.4050   Reconstruction loss: 5418333.7952\n",
            "Accuracy: 5654/6000 0.9423\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1902/2000 0.9510\n",
            "\n",
            "Epoch: 42\n",
            "Learning rate: 8.51e-09\n",
            "TRAIN loss: 2709.7589   Marginal loss: 0.4050   Reconstruction loss: 5418707.4787\n",
            "Accuracy: 5654/6000 0.9423\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1890/2000 0.9450\n",
            "\n",
            "Epoch: 43\n",
            "Learning rate: 6.81e-09\n",
            "TRAIN loss: 2710.1295   Marginal loss: 0.4050   Reconstruction loss: 5419448.6011\n",
            "Accuracy: 5649/6000 0.9415\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 44\n",
            "Learning rate: 5.44e-09\n",
            "TRAIN loss: 2709.9391   Marginal loss: 0.4050   Reconstruction loss: 5419067.8936\n",
            "Accuracy: 5650/6000 0.9417\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 45\n",
            "Learning rate: 4.36e-09\n",
            "TRAIN loss: 2709.9153   Marginal loss: 0.4050   Reconstruction loss: 5419020.3245\n",
            "Accuracy: 5646/6000 0.9410\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1895/2000 0.9475\n",
            "\n",
            "Epoch: 46\n",
            "Learning rate: 3.48e-09\n",
            "TRAIN loss: 2709.6934   Marginal loss: 0.4050   Reconstruction loss: 5418576.5000\n",
            "Accuracy: 5655/6000 0.9425\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1896/2000 0.9480\n",
            "\n",
            "Epoch: 47\n",
            "Learning rate: 2.79e-09\n",
            "TRAIN loss: 2709.8261   Marginal loss: 0.4050   Reconstruction loss: 5418841.9202\n",
            "Accuracy: 5638/6000 0.9397\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1901/2000 0.9505\n",
            "\n",
            "Epoch: 48\n",
            "Learning rate: 2.23e-09\n",
            "TRAIN loss: 2709.6037   Marginal loss: 0.4050   Reconstruction loss: 5418397.0638\n",
            "Accuracy: 5656/6000 0.9427\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1891/2000 0.9455\n",
            "\n",
            "Epoch: 49\n",
            "Learning rate: 1.78e-09\n",
            "TRAIN loss: 2709.5836   Marginal loss: 0.4050   Reconstruction loss: 5418356.8564\n",
            "Accuracy: 5643/6000 0.9405\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1889/2000 0.9445\n",
            "\n",
            "Epoch: 50\n",
            "Learning rate: 1.43e-09\n",
            "TRAIN loss: 2709.9873   Marginal loss: 0.4050   Reconstruction loss: 5419164.2580\n",
            "Accuracy: 5651/6000 0.9418\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1899/2000 0.9495\n",
            "\n",
            "Epoch: 51\n",
            "Learning rate: 1.14e-09\n",
            "TRAIN loss: 2709.3474   Marginal loss: 0.4050   Reconstruction loss: 5417884.4202\n",
            "Accuracy: 5640/6000 0.9400\n",
            "VALID loss: 2695.5836   Marginal loss: 0.4050   Reconstruction loss: 5390356.7857\n",
            "Accuracy: 1891/2000 0.9455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-b33462f3d712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-35c6d8a4da1f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt, train_loader, valid_loader, model)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L1zTaKivpznC",
        "outputId": "c9e7cdf8-6f68-4692-b579-0f6318de0f88"
      },
      "source": [
        "# evaluate(opt, valid_loader, model, 'VALID', False) \n",
        "# test_loader = loader.test_loader\n",
        "# evaluate(opt, test_loader, model, 'TEST', False)\n",
        "for data, target in test_loader:\n",
        "    for j in range(6):\n",
        "        plt.figure()\n",
        "        plt.imshow(data[j], cmap = \"gray\")\n",
        "    break"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM8J2BxNrJ1G"
      },
      "source": [
        "# Inference\n",
        "# evaluate(opt, valid_loader, model, 'VALID', True)\n",
        "for data, target in valid_loader:\n",
        "    data = data.to(torch.float32)\n",
        "    target = target.to(torch.int64)\n",
        "    batch_size = data.size(0)\n",
        "    assert target.size() == torch.Size([batch_size, opt.n_classes])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        data, target = Variable(data), Variable(target)\n",
        "    if opt.use_cuda & torch.cuda.is_available():\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "\n",
        "    output = model(data)  # (batch_size, n_classes, 16)\n",
        "\n",
        "    norms = torch.sqrt(torch.sum(output**2, dim=2))  # (batch_size, n_classes)\n",
        "    pred = norms.data.max(1, keepdim=True)[1].type(torch.LongTensor)  # (batch_size, 1)\n",
        "    label = target.max(1, keepdim=True)[1].type(torch.LongTensor)  # (batch_size, 1)\n",
        "    break\n",
        "recons = model.Decoder(output, target)\n",
        "recons = recons.view(batch_size, opt.image_size, opt.image_size)\n",
        "\n",
        "print(target[0])\n",
        "plt.figure()\n",
        "plt.imshow(recons[0].cpu().detach(), cmap = \"gray\")\n",
        "\n",
        "print(target[1])\n",
        "plt.figure()\n",
        "plt.imshow(recons[1].cpu().detach(), cmap = \"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}