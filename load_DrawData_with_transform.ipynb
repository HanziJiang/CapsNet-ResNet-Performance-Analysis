{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjArTb0QQJ5d"
   },
   "source": [
    "# *Set up*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6g5b_JdpYu_7",
    "outputId": "8355ca2d-94ca-4053-c87a-b6f8f0490ed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ndjson in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
      "Requirement already satisfied: cairocffi in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.20)\n",
      "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install ndjson\n",
    "!pip install cairocffi\n",
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2bhMSyOHU2R0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ndjson\n",
    "import pandas as pd\n",
    "import cairocffi as cairo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import imutils\n",
    "import torch.utils.data as data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjNvAQCoUDhf",
    "outputId": "9b679472-60ef-4f1c-ca04-28a20cdb030e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 8\n",
      "total training samples: 15000\n",
      "total validatoin samples: 5000\n",
      "total test samples: 5000\n"
     ]
    }
   ],
   "source": [
    "category = ['triangle', 'square', 'mushroom', 'crown', 'envelope'] # add training classes\n",
    "batch_size = 8\n",
    "print(\"batch_size: {}\".format(batch_size))\n",
    "image_size = 28\n",
    "number_per_catogory = 1000\n",
    "dataset_seed = 42\n",
    "train_ratio = 0.6\n",
    "validation_ratio = 0.2\n",
    "all_samples = len(category)*number_per_catogory\n",
    "\n",
    "np.random.seed(dataset_seed)\n",
    "random.seed(dataset_seed)\n",
    "\n",
    "TRAIN_INDICES = random.sample(list(range(all_samples)), int(all_samples*train_ratio))\n",
    "temp_INDICES = list(set(range(all_samples)) - set(TRAIN_INDICES))\n",
    "VAL_INDICES = random.sample(list(temp_INDICES), int(all_samples*validation_ratio))\n",
    "TEST_INDICES = list(set(temp_INDICES) - set(VAL_INDICES))\n",
    "print(\"total training samples:\",len(TRAIN_INDICES))\n",
    "print(\"total validatoin samples:\",len(VAL_INDICES))\n",
    "print(\"total test samples:\",len(TEST_INDICES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1i6yjKH2UCjR",
    "outputId": "9f23e9f5-7fc4-4856-ef64-f02ab9f53f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘quickDrawData’: File exists\n",
      "Copying gs://quickdraw_dataset/full/simplified/triangle.ndjson...\n",
      "/ [1/1 files][ 30.5 MiB/ 30.5 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/30.5 MiB.                                     \n",
      "Copying gs://quickdraw_dataset/full/simplified/square.ndjson...\n",
      "/ [1/1 files][ 32.0 MiB/ 32.0 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/32.0 MiB.                                     \n",
      "Copying gs://quickdraw_dataset/full/simplified/mushroom.ndjson...\n",
      "- [1/1 files][ 53.5 MiB/ 53.5 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/53.5 MiB.                                     \n",
      "Copying gs://quickdraw_dataset/full/simplified/crown.ndjson...\n",
      "- [1/1 files][ 47.7 MiB/ 47.7 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/47.7 MiB.                                     \n",
      "Copying gs://quickdraw_dataset/full/simplified/envelope.ndjson...\n",
      "/ [1/1 files][ 41.7 MiB/ 41.7 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/41.7 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Download simplified data\n",
    "!mkdir quickDrawData\n",
    "for item in category:\n",
    "  path=os.path.join('gs://quickdraw_dataset/full/simplified',item+'.ndjson')\n",
    "  !gsutil -m cp $path ./quickDrawData/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvGehKwhQYpv"
   },
   "source": [
    "# *Helper functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "T0ns2mmrxzq0"
   },
   "outputs": [],
   "source": [
    "# credit to:\n",
    "#https://github.com/googlecreativelab/quickdraw-dataset/issues/19\n",
    "\n",
    "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
    "    \"\"\"\n",
    "    padding and line_diameter are relative to the original 256x256 image.\n",
    "    \"\"\"\n",
    "    \n",
    "    original_side = 256.\n",
    "    \n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
    "    ctx = cairo.Context(surface)\n",
    "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
    "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
    "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
    "    ctx.set_line_width(line_diameter)\n",
    "\n",
    "    # scale to match the new size\n",
    "    # add padding at the edges for the line_diameter\n",
    "    # and add additional padding to account for antialiasing\n",
    "    total_padding = padding * 2. + line_diameter\n",
    "    new_scale = float(side) / float(original_side + total_padding)\n",
    "    ctx.scale(new_scale, new_scale)\n",
    "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
    "\n",
    "    raster_images = []\n",
    "    for vector_image in vector_images:\n",
    "        # clear background\n",
    "        ctx.set_source_rgb(*bg_color)\n",
    "        ctx.paint()\n",
    "        \n",
    "        bbox = np.hstack(vector_image).max(axis=1)\n",
    "        offset = ((original_side, original_side) - bbox) / 2.\n",
    "        offset = offset.reshape(-1,1)\n",
    "        centered = [stroke + offset for stroke in vector_image]\n",
    "\n",
    "        # draw strokes, this is the most cpu-intensive part\n",
    "        ctx.set_source_rgb(*fg_color)        \n",
    "        for xv, yv in centered:\n",
    "            ctx.move_to(xv[0], yv[0])\n",
    "            for x, y in zip(xv, yv):\n",
    "                ctx.line_to(x, y)\n",
    "            ctx.stroke()\n",
    "\n",
    "        data = surface.get_data()\n",
    "        raster_image = np.copy(np.asarray(data)[::4])\n",
    "        raster_images.append(raster_image)\n",
    "    \n",
    "    return raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "P1yf9Wj7yK0G"
   },
   "outputs": [],
   "source": [
    "def rotate_img(img,ang=None):\n",
    "  if ang==None:\n",
    "    angle = np.random.randint(20, 160)  # chosen uniformly between -20 and +20.\n",
    "  else:\n",
    "    angle = ang\n",
    "  # Determine the centre\n",
    "  height, width = img.shape[:2]\n",
    "  cX, cY = (width // 2, height // 2)\n",
    "  # Get the rotation matrix \n",
    "  M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "  cos = np.abs(M[0, 0])\n",
    "  sin = np.abs(M[0, 1])\n",
    "  # Compute the new bounding dimensions of the image\n",
    "  nW = int((height * sin) + (width * cos))\n",
    "  nH = int((height * cos) + (width * sin))\n",
    "  # Adjust the rotation matrix\n",
    "  M[0, 2] += (nW / 2) - cX\n",
    "  M[1, 2] += (nH / 2) - cY\n",
    "  # Perform the actual rotation\n",
    "  img = cv2.warpAffine(img, M, (nW, nH))\n",
    "  new_height, new_width = img.shape[:2]\n",
    "  new_cX, new_cY = (new_width // 2, new_height // 2)\n",
    "  crop_img = img[new_cY-20:new_cY+20, new_cX-20:new_cX+20]\n",
    "  return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "k8-CWb4Tkzx5"
   },
   "outputs": [],
   "source": [
    "def shear_img(img):\n",
    "  shear_factor = np.random.randint(10, 20)\n",
    "  shear_factor /= 100\n",
    "  height, width = img.shape[:2]\n",
    "  M = np.array([[1, abs(shear_factor), 0],[0,1,0]])\n",
    "  nW =  img.shape[1] + abs(shear_factor*img.shape[0])\n",
    "  img = cv2.warpAffine(img, M, (int(nW), img.shape[0]))\n",
    "  img = cv2.resize(img, (width,height))\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdU_crndQ69w"
   },
   "source": [
    "# *DrawDataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yc2u5UtCzi7g"
   },
   "outputs": [],
   "source": [
    "class DrawDataset(data.Dataset):\n",
    "    def __init__(self, dataset_type, image_size, categories, number_per_catogory, transformation='rotate', angle=0):\n",
    "        all_images = []\n",
    "        all_labels = []\n",
    "        all_keys = []\n",
    "        for item in categories:\n",
    "          with open(os.path.join('quickDrawData',item+'.ndjson')) as f:\n",
    "            data = ndjson.load(f)\n",
    "            df=pd.DataFrame.from_dict(data)\n",
    "            #new_df=df[df['countrycode']=='US']\n",
    "            new_df=df[df['countrycode'].isin(['CA','US'])]\n",
    "            new_df=new_df[new_df['recognized']==True]\n",
    "            all_images+=(list(new_df['drawing'].values)[:number_per_catogory])\n",
    "            all_labels+=(list(new_df['word'].values)[:number_per_catogory])\n",
    "            all_keys+=(list(new_df['key_id'].values)[:number_per_catogory])\n",
    "            \n",
    "\n",
    "        arr=vector_to_raster(all_images,side=image_size)\n",
    "        images = [x.reshape(image_size,image_size) for x in arr]\n",
    "\n",
    "        all_labels=np.array(all_labels)\n",
    "        images=np.array(images)\n",
    "        all_keys=np.array(all_keys)\n",
    "\n",
    "        if dataset_type=='test':\n",
    "          # TO DO: ADD TRANSFORMATION FOR TEST SET according to the following link\n",
    "          # https://www.cs.toronto.edu/~tijmen/affNIST/\n",
    "          if transformation==None:\n",
    "            all_labels=all_labels[TEST_INDICES]\n",
    "            images=images[TEST_INDICES]\n",
    "            all_keys=all_keys[TEST_INDICES]\n",
    "            images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
    "            images=[x/255. for x in images]\n",
    "          elif transformation=='rotate':\n",
    "            all_labels=all_labels[TEST_INDICES]\n",
    "            images=[np.pad(x, [(26, 26), (26, 26)], mode='constant', constant_values=0) for x in images[TEST_INDICES]]\n",
    "            images = [rotate_img(img, angle) for img in images]\n",
    "            images=[x/255. for x in images]\n",
    "            all_keys=all_keys[TEST_INDICES]\n",
    "          elif transformation=='shear':\n",
    "            all_labels=all_labels[TEST_INDICES]\n",
    "            images = [shear_img(img) for img in images[TEST_INDICES]]\n",
    "            all_keys=all_keys[TEST_INDICES]\n",
    "            images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
    "            images=[x/255. for x in images]\n",
    "        elif dataset_type=='train':\n",
    "          all_labels=all_labels[TRAIN_INDICES]\n",
    "          images=images[TRAIN_INDICES]\n",
    "          all_keys=all_keys[TRAIN_INDICES]\n",
    "          images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
    "          images=[x/255. for x in images]\n",
    "        else:\n",
    "          all_labels=all_labels[VAL_INDICES]\n",
    "          images=images[VAL_INDICES]\n",
    "          all_keys=all_keys[VAL_INDICES]\n",
    "          images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
    "          images=[x/255. for x in images]\n",
    "\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded = label_encoder.fit_transform(all_labels)\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "        \n",
    "        self.X = images\n",
    "        self.y = onehot_encoded\n",
    "        self.labels = all_labels\n",
    "        self.keys = all_keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index],self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kNED_RF52ucg"
   },
   "outputs": [],
   "source": [
    "# Normal train, validation, test datasets (without any transformation)\n",
    "train_dataset=DrawDataset('train', image_size, category, number_per_catogory)\n",
    "valid_dataset=DrawDataset('valid', image_size, category, number_per_catogory)\n",
    "#test_dataset=DrawDataset('test', image_size, category, number_per_catogory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Hg4fmCZKRYGx"
   },
   "outputs": [],
   "source": [
    "# Rotated test datasets\n",
    "angles = [ang for ang in range(-180, 181, 10)]\n",
    "datasets_rotate = {}\n",
    "# for ang in angles:\n",
    "#     datasets_rotate[ang] = DrawDataset('test', image_size, category, number_per_catogory, transformation='rotate', angle=ang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9T7UIvOOiIGE"
   },
   "source": [
    "# *DataLoader*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "omIYqZsH4B4o"
   },
   "outputs": [],
   "source": [
    "# Normal data loaders\n",
    "train_loader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader=DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = None   # Change when testing\n",
    "#test_loader=DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2FnsFbpPDFE-"
   },
   "outputs": [],
   "source": [
    "# Rotated test data loaders\n",
    "loaders_rotate = {}\n",
    "for ang, dataset in datasets_rotate.items():\n",
    "    loaders_rotate[ang] = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "WWnose4SYh4r"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('mnt')\n",
    "# %cd \"mnt/My Drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "edR3ctk2Po4G"
   },
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "# import torch\n",
    "# %rm -rf datasets\n",
    "# %mkdir datasets\n",
    "# %cd datasets\n",
    "# torch.save(train_dataset, 'train_dataset.pth')\n",
    "# torch.save(valid_dataset, 'valid_dataset.pth')\n",
    "# torch.save(test_dataset, 'test_dataset_original.pth')\n",
    "# for ang, data in datasets_rotate.items():\n",
    "#     torch.save(data, 'test_dataset_r{}'.format(ang))\n",
    "\n",
    "# %rm -rf ../data_loaders\n",
    "# %mkdir ../data_loaders\n",
    "# %cd ../data_loaders\n",
    "# torch.save(train_loader, 'train_loader.pth')\n",
    "# torch.save(valid_loader, 'valid_loader.pth')\n",
    "# torch.save(test_loader, 'test_loader_original.pth')\n",
    "# for ang, data in loaders_rotate.items():\n",
    "#     torch.save(data, 'test_loader_r{}'.format(ang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "owrXD9PHScDw",
    "outputId": "b6c69ae8-2d07-4d90-df04-f227245a532e"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3ebb697dac39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders_rotate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 40"
     ]
    }
   ],
   "source": [
    "#plt.imshow(loaders_rotate[40].dataset[0][0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "load_DrawData_with_transform.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
