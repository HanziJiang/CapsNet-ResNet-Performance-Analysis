{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_DrawData.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g5b_JdpYu_7",
        "outputId": "da1bc7f5-349e-489a-dd8c-5fa9536c6647"
      },
      "source": [
        "!pip install ndjson\n",
        "!pip install cairocffi"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ndjson in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Collecting cairocffi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ca/0bffed5116d21251469df200448667e90acaa5131edea869b44a3fbc73d0/cairocffi-1.2.0.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.20)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.2.0-cp37-none-any.whl size=89548 sha256=58ff8a7c7391a13169fec66374397e71fc6945e70ee66c47e373330b60b72c59\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/76/48/f1effadceea83b32e7d957dd0f92db4db8b537d7b72b4ef374\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bhMSyOHU2R0"
      },
      "source": [
        "import os\n",
        "import ndjson\n",
        "import pandas as pd\n",
        "import cairocffi as cairo\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjNvAQCoUDhf"
      },
      "source": [
        "category = ['apple','face'] # add training classes\n",
        "image_size = 28\n",
        "number_per_catogory = 1000\n",
        "dataset_seed = 42\n",
        "\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ns2mmrxzq0"
      },
      "source": [
        "# credit to:\n",
        "#https://github.com/googlecreativelab/quickdraw-dataset/issues/19\n",
        "\n",
        "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
        "    \"\"\"\n",
        "    padding and line_diameter are relative to the original 256x256 image.\n",
        "    \"\"\"\n",
        "    \n",
        "    original_side = 256.\n",
        "    \n",
        "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
        "    ctx = cairo.Context(surface)\n",
        "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
        "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
        "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
        "    ctx.set_line_width(line_diameter)\n",
        "\n",
        "    # scale to match the new size\n",
        "    # add padding at the edges for the line_diameter\n",
        "    # and add additional padding to account for antialiasing\n",
        "    total_padding = padding * 2. + line_diameter\n",
        "    new_scale = float(side) / float(original_side + total_padding)\n",
        "    ctx.scale(new_scale, new_scale)\n",
        "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
        "\n",
        "    raster_images = []\n",
        "    for vector_image in vector_images:\n",
        "        # clear background\n",
        "        ctx.set_source_rgb(*bg_color)\n",
        "        ctx.paint()\n",
        "        \n",
        "        bbox = np.hstack(vector_image).max(axis=1)\n",
        "        offset = ((original_side, original_side) - bbox) / 2.\n",
        "        offset = offset.reshape(-1,1)\n",
        "        centered = [stroke + offset for stroke in vector_image]\n",
        "\n",
        "        # draw strokes, this is the most cpu-intensive part\n",
        "        ctx.set_source_rgb(*fg_color)        \n",
        "        for xv, yv in centered:\n",
        "            ctx.move_to(xv[0], yv[0])\n",
        "            for x, y in zip(xv, yv):\n",
        "                ctx.line_to(x, y)\n",
        "            ctx.stroke()\n",
        "\n",
        "        data = surface.get_data()\n",
        "        raster_image = np.copy(np.asarray(data)[::4])\n",
        "        raster_images.append(raster_image)\n",
        "    \n",
        "    return raster_images"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i6yjKH2UCjR",
        "outputId": "c845f572-9d47-4170-9c82-c53affbeeba1"
      },
      "source": [
        "# download simplified data\n",
        "!mkdir quickDrawData\n",
        "for item in category:\n",
        "  path=os.path.join('gs://quickdraw_dataset/full/simplified',item+'.ndjson')\n",
        "  print(path)\n",
        "  !gsutil -m cp $path ./quickDrawData/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://quickdraw_dataset/full/simplified/apple.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/apple.ndjson...\n",
            "/ [1/1 files][ 56.1 MiB/ 56.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/56.1 MiB.                                     \n",
            "gs://quickdraw_dataset/full/simplified/airplain.ndjson\n",
            "CommandException: No URLs matched: gs://quickdraw_dataset/full/simplified/airplain.ndjson\n",
            "CommandException: 1 file/object could not be transferred.\n",
            "gs://quickdraw_dataset/full/simplified/face.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/face.ndjson...\n",
            "\\ [1/1 files][ 89.4 MiB/ 89.4 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/89.4 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc2u5UtCzi7g"
      },
      "source": [
        "class DrawDataset(data.Dataset):\n",
        "    def __init__(self, image_size, categories, normalize, transformation, \n",
        "                 number_per_catogory):\n",
        "        all_images = []\n",
        "        all_labels = []\n",
        "        all_keys = []\n",
        "        for item in categories:\n",
        "          with open(os.path.join('quickDrawData',item+'.ndjson')) as f:\n",
        "            print(item)\n",
        "            data = ndjson.load(f)\n",
        "            df=pd.DataFrame.from_dict(data)\n",
        "            new_df=df[df['countrycode']=='CA']\n",
        "            new_df=new_df[new_df['recognized']==True]\n",
        "            all_images+=(list(new_df['drawing'].values)[:number_per_catogory])\n",
        "            all_labels+=(list(new_df['word'].values)[:number_per_catogory])\n",
        "            all_keys+=(list(new_df['key_id'].values)[:number_per_catogory])\n",
        "\n",
        "        arr=vector_to_raster(all_images,side=image_size)\n",
        "        images = [x.reshape(image_size,image_size) for x in arr]\n",
        "        if transformation==False:\n",
        "          if normalize==True:\n",
        "            images=images/255\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        integer_encoded = label_encoder.fit_transform(all_labels)\n",
        "        onehot_encoder = OneHotEncoder(sparse=False)\n",
        "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "        \n",
        "        self.X = images\n",
        "        self.y = onehot_encoded\n",
        "        self.labels = all_labels\n",
        "        self.keys = all_keys\n",
        "        # normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index],self.y[index]"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNED_RF52ucg",
        "outputId": "9f9bffa4-e347-4e8b-d18e-d43a1092f875"
      },
      "source": [
        "dataset=DrawDataset(image_size, category, False, False, \n",
        "                 number_per_catogory)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple\n",
            "face\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB8Ralu_2iKi"
      },
      "source": [
        "def load_data(dataset, batch_size, dataset_seed):\n",
        "\n",
        "    train_set, val_set = data.random_split(dataset, \n",
        "                        [int(np.floor(len(dataset)*0.7)), int(np.floor(len(dataset)*0.3))],\n",
        "                        generator=torch.Generator().manual_seed(dataset_seed))\n",
        "\n",
        "    train_loader=DataLoader(train_set, batch_size=batch_size,shuffle=True)\n",
        "    val_loader=DataLoader(val_set, batch_size=batch_size,shuffle=False)\n",
        "    return train_loader, val_loader\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbp0ujSC25gV",
        "outputId": "d000ad89-7426-4e15-e022-2ca5af3895bc"
      },
      "source": [
        "dataset=DrawDataset(image_size, category, False, False, \n",
        "                 number_per_catogory)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple\n",
            "face\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omIYqZsH4B4o"
      },
      "source": [
        "batch_size = 32\n",
        "train_loader, val_loader= load_data(dataset,batch_size,dataset_seed)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVSLbnsUcNQe"
      },
      "source": [
        "# look at an image\n",
        "from PIL import Image\n",
        "img = Image.fromarray(images[1100])\n",
        "img.save('1100.png')\n"
      ],
      "execution_count": 146,
      "outputs": []
    }
  ]
}