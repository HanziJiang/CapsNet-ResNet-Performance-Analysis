{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_DrawData.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g5b_JdpYu_7",
        "outputId": "09594bdb-3ca9-4c2a-bc54-6c6d381260e5"
      },
      "source": [
        "!pip install ndjson\n",
        "!pip install cairocffi"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ndjson in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bhMSyOHU2R0"
      },
      "source": [
        "import os\n",
        "import ndjson\n",
        "import pandas as pd\n",
        "import cairocffi as cairo\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.utils.data import DataLoader\n",
        "import random"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjNvAQCoUDhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9189b9-10ce-4d0c-af02-6375ede6e76b"
      },
      "source": [
        "category = ['apple','face'] # add training classes\n",
        "batch_size = 32\n",
        "image_size = 28\n",
        "number_per_catogory = 5000\n",
        "dataset_seed = 42\n",
        "train_ratio = 0.6\n",
        "validation_ratio = 0.2\n",
        "all_samples = len(category)*number_per_catogory\n",
        "\n",
        "np.random.seed(dataset_seed)\n",
        "TRAIN_INDICES = random.sample(list(range(all_samples)), int(all_samples*train_ratio))\n",
        "print(len(TRAIN_INDICES))\n",
        "temp_INDICES = list(set(range(all_samples)) - set(TRAIN_INDICES))\n",
        "print(len(temp_INDICES))\n",
        "VAL_INDICES = random.sample(list(temp_INDICES), int(all_samples*validation_ratio))\n",
        "TEST_INDICES = list(set(temp_INDICES) - set(VAL_INDICES))\n",
        "print(\"total training samples:\",len(TRAIN_INDICES))\n",
        "print(\"total validatoin samples:\",len(VAL_INDICES))\n",
        "print(\"total test samples:\",len(TEST_INDICES))\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000\n",
            "4000\n",
            "total training samples: 6000\n",
            "total validatoin samples: 2000\n",
            "total test samples: 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ns2mmrxzq0"
      },
      "source": [
        "# credit to:\n",
        "#https://github.com/googlecreativelab/quickdraw-dataset/issues/19\n",
        "\n",
        "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
        "    \"\"\"\n",
        "    padding and line_diameter are relative to the original 256x256 image.\n",
        "    \"\"\"\n",
        "    \n",
        "    original_side = 256.\n",
        "    \n",
        "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
        "    ctx = cairo.Context(surface)\n",
        "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
        "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
        "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
        "    ctx.set_line_width(line_diameter)\n",
        "\n",
        "    # scale to match the new size\n",
        "    # add padding at the edges for the line_diameter\n",
        "    # and add additional padding to account for antialiasing\n",
        "    total_padding = padding * 2. + line_diameter\n",
        "    new_scale = float(side) / float(original_side + total_padding)\n",
        "    ctx.scale(new_scale, new_scale)\n",
        "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
        "\n",
        "    raster_images = []\n",
        "    for vector_image in vector_images:\n",
        "        # clear background\n",
        "        ctx.set_source_rgb(*bg_color)\n",
        "        ctx.paint()\n",
        "        \n",
        "        bbox = np.hstack(vector_image).max(axis=1)\n",
        "        offset = ((original_side, original_side) - bbox) / 2.\n",
        "        offset = offset.reshape(-1,1)\n",
        "        centered = [stroke + offset for stroke in vector_image]\n",
        "\n",
        "        # draw strokes, this is the most cpu-intensive part\n",
        "        ctx.set_source_rgb(*fg_color)        \n",
        "        for xv, yv in centered:\n",
        "            ctx.move_to(xv[0], yv[0])\n",
        "            for x, y in zip(xv, yv):\n",
        "                ctx.line_to(x, y)\n",
        "            ctx.stroke()\n",
        "\n",
        "        data = surface.get_data()\n",
        "        raster_image = np.copy(np.asarray(data)[::4])\n",
        "        raster_images.append(raster_image)\n",
        "    \n",
        "    return raster_images"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i6yjKH2UCjR",
        "outputId": "c34a66fc-d599-4c00-8162-3bf4798fad25"
      },
      "source": [
        "# download simplified data\n",
        "!mkdir quickDrawData\n",
        "for item in category:\n",
        "  path=os.path.join('gs://quickdraw_dataset/full/simplified',item+'.ndjson')\n",
        "  print(path)\n",
        "  !gsutil -m cp $path ./quickDrawData/"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://quickdraw_dataset/full/simplified/apple.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/apple.ndjson...\n",
            "| [1/1 files][ 56.1 MiB/ 56.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/56.1 MiB.                                     \n",
            "gs://quickdraw_dataset/full/simplified/face.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/face.ndjson...\n",
            "/ [1/1 files][ 89.4 MiB/ 89.4 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/89.4 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc2u5UtCzi7g"
      },
      "source": [
        "class DrawDataset(data.Dataset):\n",
        "    def __init__(self, dataset_type, image_size, categories, number_per_catogory, transformation=None):\n",
        "        all_images = []\n",
        "        all_labels = []\n",
        "        all_keys = []\n",
        "        for item in categories:\n",
        "          with open(os.path.join('quickDrawData',item+'.ndjson')) as f:\n",
        "            print(\"adding from: \",item)\n",
        "            data = ndjson.load(f)\n",
        "            df=pd.DataFrame.from_dict(data)\n",
        "            #new_df=df[df['countrycode']=='US']\n",
        "            new_df=df[df['countrycode'].isin(['CA','US'])]\n",
        "            new_df=new_df[new_df['recognized']==True]\n",
        "            all_images+=(list(new_df['drawing'].values)[:number_per_catogory])\n",
        "            all_labels+=(list(new_df['word'].values)[:number_per_catogory])\n",
        "            all_keys+=(list(new_df['key_id'].values)[:number_per_catogory])\n",
        "            \n",
        "\n",
        "        arr=vector_to_raster(all_images,side=image_size)\n",
        "        images = [x.reshape(image_size,image_size) for x in arr]\n",
        "\n",
        "        all_labels=np.array(all_labels)\n",
        "        images=np.array(images)\n",
        "        all_keys=np.array(all_keys)\n",
        "\n",
        "        if dataset_type=='test':\n",
        "          # TO DO: ADD TRANSFORMATION FOR TEST SET according to the following link\n",
        "          # https://www.cs.toronto.edu/~tijmen/affNIST/\n",
        "          print(\"building test dataset\")\n",
        "          if transformation==None:\n",
        "            all_labels=all_labels[TEST_INDICES]\n",
        "            images=images[TEST_INDICES]\n",
        "            all_keys=all_keys[TEST_INDICES]\n",
        "            images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
        "          elif transformation=='rotate':\n",
        "            all_labels=all_labels[TEST_INDICES]\n",
        "            images=[np.pad(x, [(26, 26), (26, 26)], mode='constant', constant_values=0) for x in images[TEST_INDICES]]\n",
        "            images = [rotate_img(img) for img in images]\n",
        "            #images=list(map(rotate_img, images[TEST_INDICES]))\n",
        "            all_keys=all_keys[TEST_INDICES]\n",
        "          elif transformation=='shear':\n",
        "            all_labels=all_labels[TEST_INDICES]\n",
        "            images = [shear_img(img) for img in images[TEST_INDICES]]\n",
        "            all_keys=all_keys[TEST_INDICES]\n",
        "            images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
        "        elif dataset_type=='train':\n",
        "          print(\"building \",dataset_type, \" dataset\")\n",
        "          all_labels=all_labels[TRAIN_INDICES]\n",
        "          images=images[TRAIN_INDICES]\n",
        "          all_keys=all_keys[TRAIN_INDICES]\n",
        "          images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
        "        else:\n",
        "          print(\"building \",dataset_type, \" dataset\")\n",
        "          all_labels=all_labels[VAL_INDICES]\n",
        "          images=images[VAL_INDICES]\n",
        "          all_keys=all_keys[VAL_INDICES]\n",
        "          images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
        "\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        integer_encoded = label_encoder.fit_transform(all_labels)\n",
        "        onehot_encoder = OneHotEncoder(sparse=False)\n",
        "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "        \n",
        "        self.X = images\n",
        "        self.y = onehot_encoded\n",
        "        self.labels = all_labels\n",
        "        self.keys = all_keys\n",
        "        # normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index],self.y[index]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNED_RF52ucg",
        "outputId": "26f5de1b-46fe-47ba-eb59-215ba1efa6b7"
      },
      "source": [
        "train_dataset=DrawDataset('train', image_size, category, number_per_catogory)\n",
        "val_dataset=DrawDataset('val', image_size, category, number_per_catogory)\n",
        "test_dataset=DrawDataset('test', image_size, category, number_per_catogory)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adding from:  apple\n",
            "adding from:  face\n",
            "building  train  dataset\n",
            "adding from:  apple\n",
            "adding from:  face\n",
            "building  val  dataset\n",
            "adding from:  apple\n",
            "adding from:  face\n",
            "building test dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omIYqZsH4B4o"
      },
      "source": [
        "train_loader=DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset, batch_size=batch_size,shuffle=False)\n",
        "test_loader=DataLoader(test_dataset, batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": 78,
      "outputs": []
    }
  ]
}