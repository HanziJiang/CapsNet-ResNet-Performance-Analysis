{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_DrawData.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g5b_JdpYu_7",
        "outputId": "c47a2f15-d4c0-4fa4-d7bc-912c93b85878"
      },
      "source": [
        "!pip install ndjson\n",
        "!pip install cairocffi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ndjson\n",
            "  Downloading https://files.pythonhosted.org/packages/70/c9/04ba0056011ba96a58163ebfd666d8385300bd12da1afe661a5a147758d7/ndjson-0.3.1-py2.py3-none-any.whl\n",
            "Installing collected packages: ndjson\n",
            "Successfully installed ndjson-0.3.1\n",
            "Collecting cairocffi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ca/0bffed5116d21251469df200448667e90acaa5131edea869b44a3fbc73d0/cairocffi-1.2.0.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.20)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.2.0-cp37-none-any.whl size=89548 sha256=2aa2d25ca9873e2f2672592cb565e8fba81c2c8ec510e65e476610f6c81fa549\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/76/48/f1effadceea83b32e7d957dd0f92db4db8b537d7b72b4ef374\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bhMSyOHU2R0"
      },
      "source": [
        "import os\n",
        "import ndjson\n",
        "import pandas as pd\n",
        "import cairocffi as cairo\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjNvAQCoUDhf"
      },
      "source": [
        "category = ['apple','face'] # add training classes\n",
        "image_size = 28\n",
        "number_per_catogory = 1000\n",
        "dataset_seed = 42\n",
        "train_ratio = 0.7\n",
        "all_samples = len(category)*number_per_catogory\n",
        "\n",
        "np.random.seed(dataset_seed)\n",
        "TRAIN_INDICES = list(np.random.choice(all_samples, int(all_samples*train_ratio)))\n",
        "VAL_INDICES = list(set(range(all_samples)) - set(TRAIN_INDICES))\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ns2mmrxzq0"
      },
      "source": [
        "# credit to:\n",
        "#https://github.com/googlecreativelab/quickdraw-dataset/issues/19\n",
        "\n",
        "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
        "    \"\"\"\n",
        "    padding and line_diameter are relative to the original 256x256 image.\n",
        "    \"\"\"\n",
        "    \n",
        "    original_side = 256.\n",
        "    \n",
        "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
        "    ctx = cairo.Context(surface)\n",
        "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
        "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
        "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
        "    ctx.set_line_width(line_diameter)\n",
        "\n",
        "    # scale to match the new size\n",
        "    # add padding at the edges for the line_diameter\n",
        "    # and add additional padding to account for antialiasing\n",
        "    total_padding = padding * 2. + line_diameter\n",
        "    new_scale = float(side) / float(original_side + total_padding)\n",
        "    ctx.scale(new_scale, new_scale)\n",
        "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
        "\n",
        "    raster_images = []\n",
        "    for vector_image in vector_images:\n",
        "        # clear background\n",
        "        ctx.set_source_rgb(*bg_color)\n",
        "        ctx.paint()\n",
        "        \n",
        "        bbox = np.hstack(vector_image).max(axis=1)\n",
        "        offset = ((original_side, original_side) - bbox) / 2.\n",
        "        offset = offset.reshape(-1,1)\n",
        "        centered = [stroke + offset for stroke in vector_image]\n",
        "\n",
        "        # draw strokes, this is the most cpu-intensive part\n",
        "        ctx.set_source_rgb(*fg_color)        \n",
        "        for xv, yv in centered:\n",
        "            ctx.move_to(xv[0], yv[0])\n",
        "            for x, y in zip(xv, yv):\n",
        "                ctx.line_to(x, y)\n",
        "            ctx.stroke()\n",
        "\n",
        "        data = surface.get_data()\n",
        "        raster_image = np.copy(np.asarray(data)[::4])\n",
        "        raster_images.append(raster_image)\n",
        "    \n",
        "    return raster_images"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i6yjKH2UCjR",
        "outputId": "3add8a2e-7cce-43ca-d47c-7e8d3bb123f6"
      },
      "source": [
        "# download simplified data\n",
        "!mkdir quickDrawData\n",
        "for item in category:\n",
        "  path=os.path.join('gs://quickdraw_dataset/full/simplified',item+'.ndjson')\n",
        "  print(path)\n",
        "  !gsutil -m cp $path ./quickDrawData/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://quickdraw_dataset/full/simplified/apple.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/apple.ndjson...\n",
            "\\ [1/1 files][ 56.1 MiB/ 56.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/56.1 MiB.                                     \n",
            "gs://quickdraw_dataset/full/simplified/face.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/face.ndjson...\n",
            "| [1/1 files][ 89.4 MiB/ 89.4 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/89.4 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc2u5UtCzi7g"
      },
      "source": [
        "class DrawDataset(data.Dataset):\n",
        "    def __init__(self, train, image_size, categories, number_per_catogory, transformation=None):\n",
        "        all_images = []\n",
        "        all_labels = []\n",
        "        all_keys = []\n",
        "        for item in categories:\n",
        "          with open(os.path.join('quickDrawData',item+'.ndjson')) as f:\n",
        "            print(item)\n",
        "            data = ndjson.load(f)\n",
        "            df=pd.DataFrame.from_dict(data)\n",
        "            new_df=df[df['countrycode']=='CA']\n",
        "            new_df=new_df[new_df['recognized']==True]\n",
        "            all_images+=(list(new_df['drawing'].values)[:number_per_catogory])\n",
        "            all_labels+=(list(new_df['word'].values)[:number_per_catogory])\n",
        "            all_keys+=(list(new_df['key_id'].values)[:number_per_catogory])\n",
        "\n",
        "        arr=vector_to_raster(all_images,side=image_size)\n",
        "        images = [x.reshape(image_size,image_size) for x in arr]\n",
        "\n",
        "        all_labels=np.array(all_labels)\n",
        "        images=np.array(images)\n",
        "        all_keys=np.array(all_keys)\n",
        "\n",
        "\n",
        "        if train==True:\n",
        "          all_labels=all_labels[TRAIN_INDICES]\n",
        "          images=images[TRAIN_INDICES]\n",
        "          all_keys=all_keys[TRAIN_INDICES]\n",
        "          images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
        "        else:\n",
        "          # TO DO: ADD TRANSFORMATION FOR TEST SET according to the following link\n",
        "          # https://www.cs.toronto.edu/~tijmen/affNIST/\n",
        "          if transformation==None:\n",
        "            all_labels=all_labels[VAL_INDICES]\n",
        "            images=images[VAL_INDICES]\n",
        "            all_keys=all_keys[VAL_INDICES]\n",
        "            images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
        "\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        integer_encoded = label_encoder.fit_transform(all_labels)\n",
        "        onehot_encoder = OneHotEncoder(sparse=False)\n",
        "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "        \n",
        "        self.X = images\n",
        "        self.y = onehot_encoded\n",
        "        self.labels = all_labels\n",
        "        self.keys = all_keys\n",
        "        # normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index],self.y[index]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNED_RF52ucg",
        "outputId": "b052d1ff-edfc-484a-f10f-803258bd4dbc"
      },
      "source": [
        "train_dataset=DrawDataset(True, image_size, category, number_per_catogory)\n",
        "val_dataset=DrawDataset(False, image_size, category, number_per_catogory)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple\n",
            "face\n",
            "apple\n",
            "face\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omIYqZsH4B4o"
      },
      "source": [
        "batch_size = 32\n",
        "train_loader=DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset, batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": 50,
      "outputs": []
    }
  ]
}