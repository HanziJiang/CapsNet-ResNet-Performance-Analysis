{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_DrawData.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g5b_JdpYu_7",
        "outputId": "3498a534-663b-480d-da81-2663a99dd5b1"
      },
      "source": [
        "!pip install ndjson\n",
        "!pip install cairocffi"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ndjson in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: cairocffi in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bhMSyOHU2R0"
      },
      "source": [
        "import os\n",
        "import ndjson\n",
        "import pandas as pd\n",
        "import cairocffi as cairo\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from torch.utils.data import DataLoader\n",
        "import random"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjNvAQCoUDhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246549af-89e9-490f-d17d-6a0bcaa9a241"
      },
      "source": [
        "category = ['apple','face'] # add training classes\n",
        "batch_size = 32\n",
        "image_size = 28\n",
        "number_per_catogory = 5000\n",
        "dataset_seed = 42\n",
        "train_ratio = 0.7\n",
        "all_samples = len(category)*number_per_catogory\n",
        "\n",
        "\n",
        "np.random.seed(dataset_seed)\n",
        "TRAIN_INDICES = random.sample(list(range(all_samples)), int(all_samples*train_ratio))\n",
        "VAL_INDICES = list(set(range(all_samples)) - set(TRAIN_INDICES))\n",
        "print(\"total training samples:\",len(TRAIN_INDICES))\n",
        "print(\"total validatoin samples:\",len(VAL_INDICES))\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training samples: 7000\n",
            "total validatoin samples: 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ns2mmrxzq0"
      },
      "source": [
        "# credit to:\n",
        "#https://github.com/googlecreativelab/quickdraw-dataset/issues/19\n",
        "\n",
        "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
        "    \"\"\"\n",
        "    padding and line_diameter are relative to the original 256x256 image.\n",
        "    \"\"\"\n",
        "    \n",
        "    original_side = 256.\n",
        "    \n",
        "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
        "    ctx = cairo.Context(surface)\n",
        "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
        "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
        "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
        "    ctx.set_line_width(line_diameter)\n",
        "\n",
        "    # scale to match the new size\n",
        "    # add padding at the edges for the line_diameter\n",
        "    # and add additional padding to account for antialiasing\n",
        "    total_padding = padding * 2. + line_diameter\n",
        "    new_scale = float(side) / float(original_side + total_padding)\n",
        "    ctx.scale(new_scale, new_scale)\n",
        "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
        "\n",
        "    raster_images = []\n",
        "    for vector_image in vector_images:\n",
        "        # clear background\n",
        "        ctx.set_source_rgb(*bg_color)\n",
        "        ctx.paint()\n",
        "        \n",
        "        bbox = np.hstack(vector_image).max(axis=1)\n",
        "        offset = ((original_side, original_side) - bbox) / 2.\n",
        "        offset = offset.reshape(-1,1)\n",
        "        centered = [stroke + offset for stroke in vector_image]\n",
        "\n",
        "        # draw strokes, this is the most cpu-intensive part\n",
        "        ctx.set_source_rgb(*fg_color)        \n",
        "        for xv, yv in centered:\n",
        "            ctx.move_to(xv[0], yv[0])\n",
        "            for x, y in zip(xv, yv):\n",
        "                ctx.line_to(x, y)\n",
        "            ctx.stroke()\n",
        "\n",
        "        data = surface.get_data()\n",
        "        raster_image = np.copy(np.asarray(data)[::4])\n",
        "        raster_images.append(raster_image)\n",
        "    \n",
        "    return raster_images"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i6yjKH2UCjR",
        "outputId": "f3a15380-fd1f-429a-c3e4-4b99ea165731"
      },
      "source": [
        "# download simplified data\n",
        "!mkdir quickDrawData\n",
        "for item in category:\n",
        "  path=os.path.join('gs://quickdraw_dataset/full/simplified',item+'.ndjson')\n",
        "  print(path)\n",
        "  !gsutil -m cp $path ./quickDrawData/"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘quickDrawData’: File exists\n",
            "gs://quickdraw_dataset/full/simplified/apple.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/apple.ndjson...\n",
            "- [1/1 files][ 56.1 MiB/ 56.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/56.1 MiB.                                     \n",
            "gs://quickdraw_dataset/full/simplified/face.ndjson\n",
            "Copying gs://quickdraw_dataset/full/simplified/face.ndjson...\n",
            "- [1/1 files][ 89.4 MiB/ 89.4 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/89.4 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc2u5UtCzi7g"
      },
      "source": [
        "class DrawDataset(data.Dataset):\n",
        "    def __init__(self, train, image_size, categories, number_per_catogory, transformation=None):\n",
        "        all_images = []\n",
        "        all_labels = []\n",
        "        all_keys = []\n",
        "        for item in categories:\n",
        "          with open(os.path.join('quickDrawData',item+'.ndjson')) as f:\n",
        "            print(\"adding from: \",item)\n",
        "            data = ndjson.load(f)\n",
        "            df=pd.DataFrame.from_dict(data)\n",
        "            #new_df=df[df['countrycode']=='US']\n",
        "            new_df=df[df['countrycode'].isin(['CA','US'])]\n",
        "            new_df=new_df[new_df['recognized']==True]\n",
        "            all_images+=(list(new_df['drawing'].values)[:number_per_catogory])\n",
        "            all_labels+=(list(new_df['word'].values)[:number_per_catogory])\n",
        "            all_keys+=(list(new_df['key_id'].values)[:number_per_catogory])\n",
        "            print(len(list(new_df['key_id'].values)[:number_per_catogory]))\n",
        "\n",
        "        arr=vector_to_raster(all_images,side=image_size)\n",
        "        images = [x.reshape(image_size,image_size) for x in arr]\n",
        "\n",
        "        all_labels=np.array(all_labels)\n",
        "        images=np.array(images)\n",
        "        all_keys=np.array(all_keys)\n",
        "        \n",
        "      \n",
        "        if train==True:\n",
        "          print(\"building train dataset\")\n",
        "          all_labels=all_labels[TRAIN_INDICES]\n",
        "          images=images[TRAIN_INDICES]\n",
        "          all_keys=all_keys[TRAIN_INDICES]\n",
        "          images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
        "        else:\n",
        "          # TO DO: ADD TRANSFORMATION FOR TEST SET according to the following link\n",
        "          # https://www.cs.toronto.edu/~tijmen/affNIST/\n",
        "          print(\"building validation dataset\")\n",
        "          if transformation==None:\n",
        "            all_labels=all_labels[VAL_INDICES]\n",
        "            images=images[VAL_INDICES]\n",
        "            all_keys=all_keys[VAL_INDICES]\n",
        "            images=[np.pad(x, [(6, 6), (6, 6)], mode='constant', constant_values=0) for x in images]\n",
        "\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        integer_encoded = label_encoder.fit_transform(all_labels)\n",
        "        onehot_encoder = OneHotEncoder(sparse=False)\n",
        "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "        \n",
        "        self.X = images\n",
        "        self.y = onehot_encoded\n",
        "        self.labels = all_labels\n",
        "        self.keys = all_keys\n",
        "        # normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index],self.y[index]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNED_RF52ucg",
        "outputId": "6791b47f-c597-40eb-9382-3243ac4734df"
      },
      "source": [
        "train_dataset=DrawDataset(True, image_size, category, number_per_catogory)\n",
        "val_dataset=DrawDataset(False, image_size, category, number_per_catogory)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adding from:  apple\n",
            "5000\n",
            "adding from:  face\n",
            "5000\n",
            "building train dataset\n",
            "adding from:  apple\n",
            "5000\n",
            "adding from:  face\n",
            "5000\n",
            "building validation dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omIYqZsH4B4o"
      },
      "source": [
        "\n",
        "train_loader=DataLoader(train_dataset, batch_size=batch_size,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset, batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": 66,
      "outputs": []
    }
  ]
}